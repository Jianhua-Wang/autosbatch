{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"autosbatch \u00b6 submit hundreds of jobs to slurm automatically Documentation: https://Jianhua-Wang.github.io/autosbatch GitHub: https://github.com/Jianhua-Wang/autosbatch PyPI: https://pypi.org/project/autosbatch/ Free software: MIT Features \u00b6 Sometimes, it's quite inconvenient when we submit hundreds of jobs to slurm. For example, one needs to align RNA-seq data from one hundred samples. He may start with a bash script that takes the fastq of one sample and write sbatch scripts which execute bash align.sh sample.fq multiple times. If he wants to run 50 samples at the same time, he should write 50 sbatch scripts and each script contains two align commands. Manually managing these sbatch scripts is inconvenient. autosbatch is very helpful for submitting slurm jobs automatically and it's just like the multiprocessing.Pool . Automatically submit hundreds of jobs to Slurm with a few code. The same usage as multiprocessing.Pool . Provide command line tool for people who are not familiar with Python. TODO \u00b6 Support gpu allocation Support MPI jobs Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Home"},{"location":"#autosbatch","text":"submit hundreds of jobs to slurm automatically Documentation: https://Jianhua-Wang.github.io/autosbatch GitHub: https://github.com/Jianhua-Wang/autosbatch PyPI: https://pypi.org/project/autosbatch/ Free software: MIT","title":"autosbatch"},{"location":"#features","text":"Sometimes, it's quite inconvenient when we submit hundreds of jobs to slurm. For example, one needs to align RNA-seq data from one hundred samples. He may start with a bash script that takes the fastq of one sample and write sbatch scripts which execute bash align.sh sample.fq multiple times. If he wants to run 50 samples at the same time, he should write 50 sbatch scripts and each script contains two align commands. Manually managing these sbatch scripts is inconvenient. autosbatch is very helpful for submitting slurm jobs automatically and it's just like the multiprocessing.Pool . Automatically submit hundreds of jobs to Slurm with a few code. The same usage as multiprocessing.Pool . Provide command line tool for people who are not familiar with Python.","title":"Features"},{"location":"#todo","text":"Support gpu allocation Support MPI jobs","title":"TODO"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"Top-level package for autosbatch. autosbatch \u00b6 Main module. SlurmPool \u00b6 A class for submitting jobs to Slurm. __enter__ ( self ) special \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py def __enter__ ( self ): \"\"\"Clean up the scripts and log files.\"\"\" return self __exit__ ( self , exc_type , exc_val , exc_tb ) special \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\"Clean up the scripts and log files.\"\"\" self . close () __init__ ( self , pool_size = None , ncpus_per_job = 1 , max_jobs_per_node = None , node_list = None , partition = None , max_pool_size = 1000 ) special \u00b6 Initialize a SlurmPool object. Source code in autosbatch/autosbatch.py def __init__ ( self , pool_size : Optional [ int ] = None , ncpus_per_job : int = 1 , max_jobs_per_node : Optional [ int ] = None , node_list : Optional [ List [ str ]] = None , partition : Optional [ str ] = None , max_pool_size : int = 1000 , ): \"\"\"Initialize a SlurmPool object.\"\"\" self . ncpus_per_job = ncpus_per_job self . nodes = self . get_nodes () self . _get_avail_nodes ( node_list = node_list , partition = partition ) self . node_list = list ( self . nodes . keys ()) if len ( self . node_list ) == 0 : raise RuntimeError ( 'No Nodes are qualtified.' ) self . _set_max_jobs_per_node ( max_jobs_per_node = max_jobs_per_node ) jobs_on_nodes = { k : v [ 'max_jobs' ] for k , v in self . nodes . items ()} self . jobs_on_nodes = { k : v if v <= self . max_jobs_per_node else self . max_jobs_per_node for k , v in jobs_on_nodes . items () } self . _set_pool_size ( pool_size = pool_size , max_pool_size = max_pool_size ) clean () classmethod \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py @classmethod def clean ( cls ): \"\"\"Clean up the scripts and log files.\"\"\" command = [ 'rm' , '-rf' , cls . dir_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) close ( self ) \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py def close ( self ): \"\"\"Clean up the scripts and log files.\"\"\" pass get_nodes ( sortByload = True ) classmethod \u00b6 Get nodes information from sinfo. Source code in autosbatch/autosbatch.py @classmethod def get_nodes ( cls , sortByload = True ) -> Dict : \"\"\"Get nodes information from sinfo.\"\"\" command = [ 'sinfo' , '-o' , '\"%n %e %m %a %c %C %O %R %t\"' ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) nodes = {} for line in result . stdout . splitlines (): line = line . strip ( ' \\\" ' ) if line . startswith ( 'HOSTNAMES' ): continue node , free_mem , memory , avail , cpus , free_cpus , load , partition , state = line . split () nodes [ node ] = { 'free_mem' : int ( free_mem ), 'used_mem' : int ( memory ) - int ( free_mem ), 'memory' : int ( memory ), 'AVAIL' : avail , 'cpus' : int ( cpus ), 'used_cpus' : int ( free_cpus . split ( '/' )[ 0 ]), 'free_cpus' : int ( free_cpus . split ( '/' )[ 1 ]), 'load' : float ( load ), 'partition' : partition , 'state' : state , } if sortByload : nodes = dict ( OrderedDict ( sorted ( nodes . items (), key = lambda x : ( x [ 1 ][ 'load' ], x [ 1 ][ 'used_mem' ], x [ 1 ][ 'used_cpus' ]))) ) return nodes map ( self , func , params ) \u00b6 Submit a list of commands to the cluster. Source code in autosbatch/autosbatch.py def map ( self , func : Callable , params : Iterable ): \"\"\"Submit a list of commands to the cluster.\"\"\" cmds = [ func ( i ) for i in params ] self . multi_submit ( cmds , func . __name__ ) multi_submit ( self , cmds , job_name , logging_level = 30 , shuffle = False , sleep_time = 0.5 ) \u00b6 Submit jobs to multiple nodes. Source code in autosbatch/autosbatch.py def multi_submit ( self , cmds : List [ str ], job_name : str , logging_level : int = logging . WARNING , shuffle : bool = False , sleep_time : float = 0.5 , ): \"\"\"Submit jobs to multiple nodes.\"\"\" if shuffle : import random random . shuffle ( cmds ) logger . setLevel ( logging_level ) logger . info ( f 'Found { len ( self . nodes ) } available nodes.' ) self . pool_size = min ( self . pool_size , len ( cmds )) logger . info ( f ' { len ( cmds ) : , } jobs to excute, allocated to { self . pool_size } tasks.' ) logger . info ( f 'Each task will use { self . ncpus_per_job } cpus.' ) used_nodes = {} registed_jobs = 0 for k , v in self . jobs_on_nodes . items (): used_nodes [ k ] = v registed_jobs += v if registed_jobs < self . pool_size : continue elif registed_jobs == self . pool_size : break else : used_nodes [ k ] -= registed_jobs - self . pool_size break logger . info ( f 'Used { len ( used_nodes ) } nodes.' ) logger . info ( f 'Each node will excute { max ( used_nodes . values ()) } tasks in parallel.' ) logger . info ( f ' { used_nodes } ' ) k , m = divmod ( len ( cmds ), self . pool_size ) ith = 0 task_log = {} with Progress ( TextColumn ( \" {task.description} \" ), BarColumn (), MofNCompleteColumn (), TimeRemainingColumn (), auto_refresh = False , ) as progress : for node , n_jobs in used_nodes . items (): logger . info ( f ' { node } : { n_jobs } tasks' ) task = progress . add_task ( f \"Submitting to { node } ...\" , total = n_jobs ) for _ in range ( n_jobs ): time . sleep ( sleep_time ) start , end = ith * k + min ( ith , m ), ( ith + 1 ) * k + min ( ith + 1 , m ) logger . info ( f 'Task { ith } : containing job { start } - { end - 1 } ' ) task_name = f ' { job_name } _ { ith : >03 } ' self . single_submit ( self . nodes [ node ][ 'partition' ], node , self . ncpus_per_job , cmds [ start : end ], task_name , logging_level , ) progress . update ( task , advance = 1 ) progress . refresh () ith += 1 task_log [ task_name ] = { 'node' : node , 'script' : f ' { task_name } .sh' , 'stdout' : f ' { task_name } .out.log' , 'stderr' : f ' { task_name } .err.log' , 'cmd' : cmds [ start : end ], } with open ( f ' { self . FILE_DIR } / { self . time_now } .log' , 'w' ) as f : logger . info ( f 'Writing task log to { self . FILE_DIR } / { self . time_now } .log' ) json . dump ( task_log , f , indent = 4 ) single_submit ( partition , node , cpus_per_task , cmds , job_name = 'job' , logging_level = 30 ) classmethod \u00b6 Submit a single job. Source code in autosbatch/autosbatch.py @classmethod def single_submit ( cls , partition : str , node : str , cpus_per_task : int , cmds : Union [ str , List [ str ]], job_name : str = 'job' , logging_level : int = logging . WARNING , ): \"\"\"Submit a single job.\"\"\" logger . setLevel ( logging_level ) Path ( cls . SCRIPTS_DIR ) . mkdir ( parents = True , exist_ok = True ) Path ( cls . LOG_DIR ) . mkdir ( parents = True , exist_ok = True ) templateLoader = FileSystemLoader ( searchpath = f \" { os . path . dirname ( os . path . realpath ( __file__ )) } /template\" ) env = Environment ( loader = templateLoader ) template = env . get_template ( cls . CPU_OpenMP_TEMPLATE ) if isinstance ( cmds , str ): cmds = [ cmds ] output_from_parsed_template = template . render ( job_name = job_name , partition = partition , node = node , cpus_per_task = cpus_per_task , cmds = ' \\n ' . join ( cmds ), log_dir = cls . LOG_DIR , ) script_path = f ' { cls . SCRIPTS_DIR } / { job_name } .sh' with open ( script_path , 'w' ) as f : f . write ( output_from_parsed_template ) command = [ 'chmod' , '755' , script_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) command = [ 'sbatch' , script_path ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) slurm_id = result . stdout . strip () . split ()[ - 1 ] logger . info ( f 'Sumbitted Task: { job_name } to { node } , containing { len ( cmds ) } jobs. Slurm ID: { slurm_id } ' ) logger . debug ( f 'Commands: { cmds } ' ) starmap ( self , func , params ) \u00b6 Submit a list of commands to the cluster. Source code in autosbatch/autosbatch.py def starmap ( self , func : Callable , params : Iterable [ Iterable ]): \"\"\"Submit a list of commands to the cluster.\"\"\" cmds = [ func ( * i ) for i in params ] self . multi_submit ( cmds , func . __name__ ) cli \u00b6 Console script for autosbatch. clean () \u00b6 Remove all scripts and logs. Source code in autosbatch/cli.py @app . command () def clean (): \"\"\"Remove all scripts and logs.\"\"\" SlurmPool . clean () logger . setLevel ( config [ 'logging_level' ]) logger . info ( 'Cleaned all scripts and logs.' ) main ( version =< typer . models . OptionInfo object at 0x7f016d4e4dc0 > , verbose =< typer . models . OptionInfo object at 0x7f016d4e4df0 > , dev =< typer . models . OptionInfo object at 0x7f016d4e4e20 > ) \u00b6 Submit jobs to slurm cluster, without writing slurm script files. Source code in autosbatch/cli.py @app . callback ( invoke_without_command = True , no_args_is_help = True ) def main ( version : bool = typer . Option ( False , '--version' , '-V' , help = 'Show version.' ), verbose : bool = typer . Option ( False , '--verbose' , '-v' , help = 'Show verbose info.' ), dev : bool = typer . Option ( False , '--dev' , help = 'Show dev info.' ), ): \"\"\"Submit jobs to slurm cluster, without writing slurm script files.\"\"\" console = Console () console . rule ( \"[bold blue]AutoSbatch[/bold blue]\" ) if version : typer . echo ( f 'AutoSbatch version: { __version__ } ' ) raise typer . Exit () if verbose : config [ 'logging_level' ] = logging . INFO logger . info ( 'Verbose mode is on.' ) if dev : config [ 'logging_level' ] = logging . DEBUG logger . debug ( 'Dev mode is on.' ) multi_job ( pool_size =< typer . models . OptionInfo object at 0x7f016d4e4b50 > , ncpus_per_job =< typer . models . OptionInfo object at 0x7f016d4e4b80 > , max_jobs_per_node =< typer . models . OptionInfo object at 0x7f016d4e4bb0 > , node_list =< typer . models . OptionInfo object at 0x7f016d4e4be0 > , partition =< typer . models . OptionInfo object at 0x7f016d4e4c10 > , job_name =< typer . models . OptionInfo object at 0x7f016d4e4c40 > , cmdfile =< typer . models . ArgumentInfo object at 0x7f016d4e4c70 > ) \u00b6 Submit multiple jobs to slurm cluster. Source code in autosbatch/cli.py @app . command () def multi_job ( pool_size : int = typer . Option ( None , '--pool-size' , '-p' , min = 0 , max = 1000 , help = 'Number of jobs to submit at the same time.' ), ncpus_per_job : int = typer . Option ( 1 , '--ncpus-per-job' , '-n' , help = 'Number of cpus per job.' ), max_jobs_per_node : int = typer . Option ( None , '--max-jobs-per-node' , '-m' , help = 'Maximum number of jobs to submit to a single node.' ), node_list : List [ str ] = typer . Option ( None , '--node-list' , '-l' , help = 'List of nodes to submit jobs to. e.g. \"-l node1 -l node2 -l node3\"' ), partition : str = typer . Option ( None , '--partition' , '-P' , help = 'Partition to submit jobs to.' ), job_name : str = typer . Option ( 'job' , '--job-name' , '-j' , help = 'Name of the job.' ), cmdfile : Path = typer . Argument ( ... , help = 'Path to the command file.' ), ): \"\"\"Submit multiple jobs to slurm cluster.\"\"\" with open ( cmdfile , 'r' ) as f : cmds = f . readlines () cmds = [ cmd . strip () for cmd in cmds ] p = SlurmPool ( pool_size = pool_size , ncpus_per_job = ncpus_per_job , max_jobs_per_node = max_jobs_per_node , node_list = node_list , partition = partition , ) p . multi_submit ( cmds = cmds , job_name = job_name , logging_level = config [ 'logging_level' ]) single_job ( ncpus =< typer . models . OptionInfo object at 0x7f016d4e4a30 > , node =< typer . models . OptionInfo object at 0x7f016d4e4a60 > , partition =< typer . models . OptionInfo object at 0x7f016d4e4a90 > , job_name =< typer . models . OptionInfo object at 0x7f016d4e4ac0 > , cmd =< typer . models . ArgumentInfo object at 0x7f016d4e4af0 > ) \u00b6 Submit a single job to slurm cluster. Source code in autosbatch/cli.py @app . command () def single_job ( ncpus : int = typer . Option ( 1 , '--ncpus' , '-n' , help = 'Number of cpus.' ), node : str = typer . Option ( None , '--node' , '-N' , help = 'Node to submit job to.' ), partition : str = typer . Option ( None , '--partition' , '-P' , help = 'Partition to submit jobs to.' ), job_name : str = typer . Option ( 'job' , '--job-name' , '-j' , help = 'Name of the job.' ), cmd : List [ str ] = typer . Argument ( ... , help = 'Command to run.' ), ): \"\"\"Submit a single job to slurm cluster.\"\"\" cmd = [ ' ' . join ( cmd )] if node : node_list : Optional [ List ] = [ node ] else : node_list = None p = SlurmPool ( pool_size = 1 , ncpus_per_job = ncpus , node_list = node_list , partition = partition , ) p . multi_submit ( cmds = cmd , job_name = job_name , logging_level = config [ 'logging_level' ]) logger \u00b6 Logging configuration for autosbatch.","title":"Modules"},{"location":"api/#autosbatch.autosbatch","text":"Main module.","title":"autosbatch"},{"location":"api/#autosbatch.autosbatch.SlurmPool","text":"A class for submitting jobs to Slurm.","title":"SlurmPool"},{"location":"api/#autosbatch.autosbatch.SlurmPool.__enter__","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py def __enter__ ( self ): \"\"\"Clean up the scripts and log files.\"\"\" return self","title":"__enter__()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.__exit__","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\"Clean up the scripts and log files.\"\"\" self . close ()","title":"__exit__()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.__init__","text":"Initialize a SlurmPool object. Source code in autosbatch/autosbatch.py def __init__ ( self , pool_size : Optional [ int ] = None , ncpus_per_job : int = 1 , max_jobs_per_node : Optional [ int ] = None , node_list : Optional [ List [ str ]] = None , partition : Optional [ str ] = None , max_pool_size : int = 1000 , ): \"\"\"Initialize a SlurmPool object.\"\"\" self . ncpus_per_job = ncpus_per_job self . nodes = self . get_nodes () self . _get_avail_nodes ( node_list = node_list , partition = partition ) self . node_list = list ( self . nodes . keys ()) if len ( self . node_list ) == 0 : raise RuntimeError ( 'No Nodes are qualtified.' ) self . _set_max_jobs_per_node ( max_jobs_per_node = max_jobs_per_node ) jobs_on_nodes = { k : v [ 'max_jobs' ] for k , v in self . nodes . items ()} self . jobs_on_nodes = { k : v if v <= self . max_jobs_per_node else self . max_jobs_per_node for k , v in jobs_on_nodes . items () } self . _set_pool_size ( pool_size = pool_size , max_pool_size = max_pool_size )","title":"__init__()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.clean","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py @classmethod def clean ( cls ): \"\"\"Clean up the scripts and log files.\"\"\" command = [ 'rm' , '-rf' , cls . dir_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True )","title":"clean()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.close","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py def close ( self ): \"\"\"Clean up the scripts and log files.\"\"\" pass","title":"close()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.get_nodes","text":"Get nodes information from sinfo. Source code in autosbatch/autosbatch.py @classmethod def get_nodes ( cls , sortByload = True ) -> Dict : \"\"\"Get nodes information from sinfo.\"\"\" command = [ 'sinfo' , '-o' , '\"%n %e %m %a %c %C %O %R %t\"' ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) nodes = {} for line in result . stdout . splitlines (): line = line . strip ( ' \\\" ' ) if line . startswith ( 'HOSTNAMES' ): continue node , free_mem , memory , avail , cpus , free_cpus , load , partition , state = line . split () nodes [ node ] = { 'free_mem' : int ( free_mem ), 'used_mem' : int ( memory ) - int ( free_mem ), 'memory' : int ( memory ), 'AVAIL' : avail , 'cpus' : int ( cpus ), 'used_cpus' : int ( free_cpus . split ( '/' )[ 0 ]), 'free_cpus' : int ( free_cpus . split ( '/' )[ 1 ]), 'load' : float ( load ), 'partition' : partition , 'state' : state , } if sortByload : nodes = dict ( OrderedDict ( sorted ( nodes . items (), key = lambda x : ( x [ 1 ][ 'load' ], x [ 1 ][ 'used_mem' ], x [ 1 ][ 'used_cpus' ]))) ) return nodes","title":"get_nodes()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.map","text":"Submit a list of commands to the cluster. Source code in autosbatch/autosbatch.py def map ( self , func : Callable , params : Iterable ): \"\"\"Submit a list of commands to the cluster.\"\"\" cmds = [ func ( i ) for i in params ] self . multi_submit ( cmds , func . __name__ )","title":"map()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.multi_submit","text":"Submit jobs to multiple nodes. Source code in autosbatch/autosbatch.py def multi_submit ( self , cmds : List [ str ], job_name : str , logging_level : int = logging . WARNING , shuffle : bool = False , sleep_time : float = 0.5 , ): \"\"\"Submit jobs to multiple nodes.\"\"\" if shuffle : import random random . shuffle ( cmds ) logger . setLevel ( logging_level ) logger . info ( f 'Found { len ( self . nodes ) } available nodes.' ) self . pool_size = min ( self . pool_size , len ( cmds )) logger . info ( f ' { len ( cmds ) : , } jobs to excute, allocated to { self . pool_size } tasks.' ) logger . info ( f 'Each task will use { self . ncpus_per_job } cpus.' ) used_nodes = {} registed_jobs = 0 for k , v in self . jobs_on_nodes . items (): used_nodes [ k ] = v registed_jobs += v if registed_jobs < self . pool_size : continue elif registed_jobs == self . pool_size : break else : used_nodes [ k ] -= registed_jobs - self . pool_size break logger . info ( f 'Used { len ( used_nodes ) } nodes.' ) logger . info ( f 'Each node will excute { max ( used_nodes . values ()) } tasks in parallel.' ) logger . info ( f ' { used_nodes } ' ) k , m = divmod ( len ( cmds ), self . pool_size ) ith = 0 task_log = {} with Progress ( TextColumn ( \" {task.description} \" ), BarColumn (), MofNCompleteColumn (), TimeRemainingColumn (), auto_refresh = False , ) as progress : for node , n_jobs in used_nodes . items (): logger . info ( f ' { node } : { n_jobs } tasks' ) task = progress . add_task ( f \"Submitting to { node } ...\" , total = n_jobs ) for _ in range ( n_jobs ): time . sleep ( sleep_time ) start , end = ith * k + min ( ith , m ), ( ith + 1 ) * k + min ( ith + 1 , m ) logger . info ( f 'Task { ith } : containing job { start } - { end - 1 } ' ) task_name = f ' { job_name } _ { ith : >03 } ' self . single_submit ( self . nodes [ node ][ 'partition' ], node , self . ncpus_per_job , cmds [ start : end ], task_name , logging_level , ) progress . update ( task , advance = 1 ) progress . refresh () ith += 1 task_log [ task_name ] = { 'node' : node , 'script' : f ' { task_name } .sh' , 'stdout' : f ' { task_name } .out.log' , 'stderr' : f ' { task_name } .err.log' , 'cmd' : cmds [ start : end ], } with open ( f ' { self . FILE_DIR } / { self . time_now } .log' , 'w' ) as f : logger . info ( f 'Writing task log to { self . FILE_DIR } / { self . time_now } .log' ) json . dump ( task_log , f , indent = 4 )","title":"multi_submit()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.single_submit","text":"Submit a single job. Source code in autosbatch/autosbatch.py @classmethod def single_submit ( cls , partition : str , node : str , cpus_per_task : int , cmds : Union [ str , List [ str ]], job_name : str = 'job' , logging_level : int = logging . WARNING , ): \"\"\"Submit a single job.\"\"\" logger . setLevel ( logging_level ) Path ( cls . SCRIPTS_DIR ) . mkdir ( parents = True , exist_ok = True ) Path ( cls . LOG_DIR ) . mkdir ( parents = True , exist_ok = True ) templateLoader = FileSystemLoader ( searchpath = f \" { os . path . dirname ( os . path . realpath ( __file__ )) } /template\" ) env = Environment ( loader = templateLoader ) template = env . get_template ( cls . CPU_OpenMP_TEMPLATE ) if isinstance ( cmds , str ): cmds = [ cmds ] output_from_parsed_template = template . render ( job_name = job_name , partition = partition , node = node , cpus_per_task = cpus_per_task , cmds = ' \\n ' . join ( cmds ), log_dir = cls . LOG_DIR , ) script_path = f ' { cls . SCRIPTS_DIR } / { job_name } .sh' with open ( script_path , 'w' ) as f : f . write ( output_from_parsed_template ) command = [ 'chmod' , '755' , script_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) command = [ 'sbatch' , script_path ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) slurm_id = result . stdout . strip () . split ()[ - 1 ] logger . info ( f 'Sumbitted Task: { job_name } to { node } , containing { len ( cmds ) } jobs. Slurm ID: { slurm_id } ' ) logger . debug ( f 'Commands: { cmds } ' )","title":"single_submit()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.starmap","text":"Submit a list of commands to the cluster. Source code in autosbatch/autosbatch.py def starmap ( self , func : Callable , params : Iterable [ Iterable ]): \"\"\"Submit a list of commands to the cluster.\"\"\" cmds = [ func ( * i ) for i in params ] self . multi_submit ( cmds , func . __name__ )","title":"starmap()"},{"location":"api/#autosbatch.cli","text":"Console script for autosbatch.","title":"cli"},{"location":"api/#autosbatch.cli.clean","text":"Remove all scripts and logs. Source code in autosbatch/cli.py @app . command () def clean (): \"\"\"Remove all scripts and logs.\"\"\" SlurmPool . clean () logger . setLevel ( config [ 'logging_level' ]) logger . info ( 'Cleaned all scripts and logs.' )","title":"clean()"},{"location":"api/#autosbatch.cli.main","text":"Submit jobs to slurm cluster, without writing slurm script files. Source code in autosbatch/cli.py @app . callback ( invoke_without_command = True , no_args_is_help = True ) def main ( version : bool = typer . Option ( False , '--version' , '-V' , help = 'Show version.' ), verbose : bool = typer . Option ( False , '--verbose' , '-v' , help = 'Show verbose info.' ), dev : bool = typer . Option ( False , '--dev' , help = 'Show dev info.' ), ): \"\"\"Submit jobs to slurm cluster, without writing slurm script files.\"\"\" console = Console () console . rule ( \"[bold blue]AutoSbatch[/bold blue]\" ) if version : typer . echo ( f 'AutoSbatch version: { __version__ } ' ) raise typer . Exit () if verbose : config [ 'logging_level' ] = logging . INFO logger . info ( 'Verbose mode is on.' ) if dev : config [ 'logging_level' ] = logging . DEBUG logger . debug ( 'Dev mode is on.' )","title":"main()"},{"location":"api/#autosbatch.cli.multi_job","text":"Submit multiple jobs to slurm cluster. Source code in autosbatch/cli.py @app . command () def multi_job ( pool_size : int = typer . Option ( None , '--pool-size' , '-p' , min = 0 , max = 1000 , help = 'Number of jobs to submit at the same time.' ), ncpus_per_job : int = typer . Option ( 1 , '--ncpus-per-job' , '-n' , help = 'Number of cpus per job.' ), max_jobs_per_node : int = typer . Option ( None , '--max-jobs-per-node' , '-m' , help = 'Maximum number of jobs to submit to a single node.' ), node_list : List [ str ] = typer . Option ( None , '--node-list' , '-l' , help = 'List of nodes to submit jobs to. e.g. \"-l node1 -l node2 -l node3\"' ), partition : str = typer . Option ( None , '--partition' , '-P' , help = 'Partition to submit jobs to.' ), job_name : str = typer . Option ( 'job' , '--job-name' , '-j' , help = 'Name of the job.' ), cmdfile : Path = typer . Argument ( ... , help = 'Path to the command file.' ), ): \"\"\"Submit multiple jobs to slurm cluster.\"\"\" with open ( cmdfile , 'r' ) as f : cmds = f . readlines () cmds = [ cmd . strip () for cmd in cmds ] p = SlurmPool ( pool_size = pool_size , ncpus_per_job = ncpus_per_job , max_jobs_per_node = max_jobs_per_node , node_list = node_list , partition = partition , ) p . multi_submit ( cmds = cmds , job_name = job_name , logging_level = config [ 'logging_level' ])","title":"multi_job()"},{"location":"api/#autosbatch.cli.single_job","text":"Submit a single job to slurm cluster. Source code in autosbatch/cli.py @app . command () def single_job ( ncpus : int = typer . Option ( 1 , '--ncpus' , '-n' , help = 'Number of cpus.' ), node : str = typer . Option ( None , '--node' , '-N' , help = 'Node to submit job to.' ), partition : str = typer . Option ( None , '--partition' , '-P' , help = 'Partition to submit jobs to.' ), job_name : str = typer . Option ( 'job' , '--job-name' , '-j' , help = 'Name of the job.' ), cmd : List [ str ] = typer . Argument ( ... , help = 'Command to run.' ), ): \"\"\"Submit a single job to slurm cluster.\"\"\" cmd = [ ' ' . join ( cmd )] if node : node_list : Optional [ List ] = [ node ] else : node_list = None p = SlurmPool ( pool_size = 1 , ncpus_per_job = ncpus , node_list = node_list , partition = partition , ) p . multi_submit ( cmds = cmd , job_name = job_name , logging_level = config [ 'logging_level' ])","title":"single_job()"},{"location":"api/#autosbatch.logger","text":"Logging configuration for autosbatch.","title":"logger"},{"location":"changelog/","text":"Changelog \u00b6 [0.1.7] - 2022-12-19 \u00b6 Added \u00b6 Changed \u00b6 disable auto_refresh progress bar Fixed \u00b6 [0.1.0] - 2022-12-16 \u00b6 Here we would have the update steps for 1.2.4 for people to follow. Added \u00b6 Changed \u00b6 PROJECTNAME-ZZZZ PATCH Drupal.org is now used for composer. Fixed \u00b6 PROJECTNAME-TTTT PATCH Add logic to runsheet teaser delete to delete corresponding schedule cards. [0.1.1] - 2022-12-16 \u00b6 Added \u00b6 Changed \u00b6 Fixed \u00b6 PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution [0.1.2] - 2022-12-16 \u00b6 Added \u00b6 Changed \u00b6 Fixed \u00b6 PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution [0.1.3] - 2022-12-17 \u00b6 Added \u00b6 Changed \u00b6 Reconstruct the project structure Fixed \u00b6 [0.1.4] - 2022-12-18 \u00b6 Added \u00b6 Changed \u00b6 Use jinja2 as sbatch template change script dir to .autosbatch get rid of pandas replace call with subprocess.run speed up by remove append Add a logger save job information to a file Fixed \u00b6 [0.1.5] - 2022-12-19 \u00b6 Added \u00b6 clean command multi submit command single submit command Changed \u00b6 replace click with typer Fixed \u00b6 [0.1.6] - 2022-12-19 \u00b6 Added \u00b6 support context manager add docs Changed \u00b6 Fixed \u00b6","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#017-2022-12-19","text":"","title":"[0.1.7] - 2022-12-19"},{"location":"changelog/#added","text":"","title":"Added"},{"location":"changelog/#changed","text":"disable auto_refresh progress bar","title":"Changed"},{"location":"changelog/#fixed","text":"","title":"Fixed"},{"location":"changelog/#010-2022-12-16","text":"Here we would have the update steps for 1.2.4 for people to follow.","title":"[0.1.0] - 2022-12-16"},{"location":"changelog/#added_1","text":"","title":"Added"},{"location":"changelog/#changed_1","text":"PROJECTNAME-ZZZZ PATCH Drupal.org is now used for composer.","title":"Changed"},{"location":"changelog/#fixed_1","text":"PROJECTNAME-TTTT PATCH Add logic to runsheet teaser delete to delete corresponding schedule cards.","title":"Fixed"},{"location":"changelog/#011-2022-12-16","text":"","title":"[0.1.1] - 2022-12-16"},{"location":"changelog/#added_2","text":"","title":"Added"},{"location":"changelog/#changed_2","text":"","title":"Changed"},{"location":"changelog/#fixed_2","text":"PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution","title":"Fixed"},{"location":"changelog/#012-2022-12-16","text":"","title":"[0.1.2] - 2022-12-16"},{"location":"changelog/#added_3","text":"","title":"Added"},{"location":"changelog/#changed_3","text":"","title":"Changed"},{"location":"changelog/#fixed_3","text":"PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution","title":"Fixed"},{"location":"changelog/#013-2022-12-17","text":"","title":"[0.1.3] - 2022-12-17"},{"location":"changelog/#added_4","text":"","title":"Added"},{"location":"changelog/#changed_4","text":"Reconstruct the project structure","title":"Changed"},{"location":"changelog/#fixed_4","text":"","title":"Fixed"},{"location":"changelog/#014-2022-12-18","text":"","title":"[0.1.4] - 2022-12-18"},{"location":"changelog/#added_5","text":"","title":"Added"},{"location":"changelog/#changed_5","text":"Use jinja2 as sbatch template change script dir to .autosbatch get rid of pandas replace call with subprocess.run speed up by remove append Add a logger save job information to a file","title":"Changed"},{"location":"changelog/#fixed_5","text":"","title":"Fixed"},{"location":"changelog/#015-2022-12-19","text":"","title":"[0.1.5] - 2022-12-19"},{"location":"changelog/#added_6","text":"clean command multi submit command single submit command","title":"Added"},{"location":"changelog/#changed_6","text":"replace click with typer","title":"Changed"},{"location":"changelog/#fixed_6","text":"","title":"Fixed"},{"location":"changelog/#016-2022-12-19","text":"","title":"[0.1.6] - 2022-12-19"},{"location":"changelog/#added_7","text":"support context manager add docs","title":"Added"},{"location":"changelog/#changed_7","text":"","title":"Changed"},{"location":"changelog/#fixed_7","text":"","title":"Fixed"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/Jianhua-Wang/autosbatch/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 autosbatch could always use more documentation, whether as part of the official autosbatch docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/Jianhua-Wang/autosbatch/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up autosbatch for local development. Fork the autosbatch repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/autosbatch.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/Jianhua-Wang/autosbatch/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 $ poetry run pytest tests/test_autosbatch.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/Jianhua-Wang/autosbatch/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"autosbatch could always use more documentation, whether as part of the official autosbatch docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/Jianhua-Wang/autosbatch/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up autosbatch for local development. Fork the autosbatch repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/autosbatch.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/Jianhua-Wang/autosbatch/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"$ poetry run pytest tests/test_autosbatch.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install autosbatch, run this command in your terminal: $ pip install autosbatch This is the preferred method to install autosbatch, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for autosbatch can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/Jianhua-Wang/autosbatch Or download the tarball : $ curl -OJL https://github.com/Jianhua-Wang/autosbatch/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install autosbatch, run this command in your terminal: $ pip install autosbatch This is the preferred method to install autosbatch, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for autosbatch can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/Jianhua-Wang/autosbatch Or download the tarball : $ curl -OJL https://github.com/Jianhua-Wang/autosbatch/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 Usage for package \u00b6 Import \u00b6 import autosbatch # or import SlurmPool directly from autosbatch import SlurmPool submit single job \u00b6 run sleep 10 on node cpu01 on cpuPartition paritition. SlurmPool . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = 'sleep 10' , job_name = 'test' , job_id = '001' ) or run a job containing two steps, e.g. echo hello and sleep 10 SlurmPool . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = [ 'echo hello' , 'sleep 10' ], job_name = 'test' , job_id = '001' ) submit multiple job \u00b6 TODO: compare multiprocessing.Pool.map TODO: add with syntax Just like multiprocessing.Pool.map # construct the excutor def sleep ( time ): cmd = f 'sleep { time } ' return cmd # prepare the param for each excutor params = range ( 10 ) # submit to parallel run p = SlurmPool ( 10 ) p . map ( sleep , params ) multiple parameters (similar with multiprocessing.Pool.starmap ) # construct the excutor def echo_sleep ( text , time ): cmd = f 'echo { text } && sleep { time } ' return cmd # prepare the params for each excutor params = [] for text in range ( 5 ): for time in range ( 6 ): params . append ([ text , time ]) # submit to parallel run p = SlurmPool ( 10 ) p . starmap ( echo_sleep , params ) The sbatch scripts are put in ./autosbatch/$timenow/script . The error and stdout logs are in ./autosbatch/$timenow/log . remove script dir: SlurmPool . clean () Custom the job Pool: p = SlurmPool ( pool_size = None , #how many jobs run in parallel, use all resources if not specify. ncpus_per_job = 2 , #how many cpus per job use max_jobs_per_node = None , #how many jobs can a node run at most node_list = None # use all nodes if not specify ) Usage for CLI tool \u00b6 help message \u00b6 $ autosbatch --help Usage: autosbatch [ OPTIONS ] COMMAND [ ARGS ] ... Submit jobs to slurm cluster, without writing slurm script files. \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --version -V Show version. \u2502 \u2502 --verbose -v Show verbose info. \u2502 \u2502 --dev Show dev info. \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 clean Remove all scripts and logs. \u2502 \u2502 multi-job Submit multiple jobs to slurm cluster. \u2502 \u2502 single-job Submit a single job to slurm cluster. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f Command: single-job \u00b6 $ autosbatch single-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch single-job [ OPTIONS ] CMD... Submit a single job to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmd CMD... Command to run. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --ncpus -n INTEGER Number of cpus. [ default: 1 ] \u2502 \u2502 --node -N TEXT Node to submit job to. [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs to. [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. [ default: job ] \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f run example command such as sleep 10 autosbatch single-job sleep 10 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :13:46 ] WARNING Hyperthreading is enabled on cpu14, ncpus_per_job is set to 2 . Command: multi-job \u00b6 $ autosbatch multi-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch multi-job [ OPTIONS ] CMDFILE Submit multiple jobs to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmdfile PATH Path to the command file. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --pool-size -p INTEGER RANGE Number of jobs to submit \u2502 \u2502 [ 0 < = x< = 1000 ] at the same time. \u2502 \u2502 [ default: None ] \u2502 \u2502 --ncpus-per-job -n INTEGER Number of cpus per job. \u2502 \u2502 [ default: 1 ] \u2502 \u2502 --max-jobs-per-node -m INTEGER Maximum number of jobs \u2502 \u2502 to submit to a single \u2502 \u2502 node. \u2502 \u2502 [ default: None ] \u2502 \u2502 --node-list -l TEXT List of nodes to submit \u2502 \u2502 jobs to. e.g. \"-l node1 \u2502 \u2502 -l node2 -l node3\" \u2502 \u2502 [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs \u2502 \u2502 to. \u2502 \u2502 [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. \u2502 \u2502 [ default: job ] \u2502 \u2502 --help -h Show this message and \u2502 \u2502 exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f submit 10 commands to slurm Step1. write the commands into a text file, one command per line. $ cat ./cmd.sh sleep 0 sleep 1 sleep 2 sleep 3 sleep 4 sleep 5 sleep 6 sleep 7 sleep 8 sleep 9 Step2 run multi-job command $ autosbatch multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Command: clean \u00b6 remove the directory contains scripts and logs autosbatch clean enable verbose \u00b6 add -v or --verbose between autosbatch and command e.g.: $ autosbatch -v multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :21:44 ] INFO Verbose mode is on. INFO Found 2 available nodes. INFO 10 jobs to excute, allocated to 6 tasks. INFO Each task will use 1 cpus. INFO Used 2 nodes. INFO Each node will excute 3 tasks in parallel. INFO { 'gpu02' : 3 , 'gpu03' : 3 } INFO gpu02: 3 tasks INFO Task 0 : containing job 0 -1 INFO Sumbitted Task: job_000 to gpu02, containing 2 jobs. Slurm ID: 254554 [ 22 :21:45 ] INFO Task 1 : containing job 2 -3 INFO Sumbitted Task: job_001 to gpu02, containing 2 jobs. Slurm ID: 254555 INFO Task 2 : containing job 4 -5 [ 22 :21:46 ] INFO Sumbitted Task: job_002 to gpu02, containing 2 jobs. Slurm ID: 254556 INFO gpu03: 3 tasks INFO Task 3 : containing job 6 -7 INFO Sumbitted Task: job_003 to gpu03, containing 2 jobs. Slurm ID: 254557 [ 22 :21:47 ] INFO Task 4 : containing job 8 -8 INFO Sumbitted Task: job_004 to gpu03, containing 1 jobs. Slurm ID: 254558 INFO Task 5 : containing job 9 -9 INFO Sumbitted Task: job_005 to gpu03, containing 1 jobs. Slurm ID: 254559 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 INFO Writing task log to .autosbatch/1219222144/1219222144.log","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#usage-for-package","text":"","title":"Usage for package"},{"location":"usage/#import","text":"import autosbatch # or import SlurmPool directly from autosbatch import SlurmPool","title":"Import"},{"location":"usage/#submit-single-job","text":"run sleep 10 on node cpu01 on cpuPartition paritition. SlurmPool . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = 'sleep 10' , job_name = 'test' , job_id = '001' ) or run a job containing two steps, e.g. echo hello and sleep 10 SlurmPool . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = [ 'echo hello' , 'sleep 10' ], job_name = 'test' , job_id = '001' )","title":"submit single job"},{"location":"usage/#submit-multiple-job","text":"TODO: compare multiprocessing.Pool.map TODO: add with syntax Just like multiprocessing.Pool.map # construct the excutor def sleep ( time ): cmd = f 'sleep { time } ' return cmd # prepare the param for each excutor params = range ( 10 ) # submit to parallel run p = SlurmPool ( 10 ) p . map ( sleep , params ) multiple parameters (similar with multiprocessing.Pool.starmap ) # construct the excutor def echo_sleep ( text , time ): cmd = f 'echo { text } && sleep { time } ' return cmd # prepare the params for each excutor params = [] for text in range ( 5 ): for time in range ( 6 ): params . append ([ text , time ]) # submit to parallel run p = SlurmPool ( 10 ) p . starmap ( echo_sleep , params ) The sbatch scripts are put in ./autosbatch/$timenow/script . The error and stdout logs are in ./autosbatch/$timenow/log . remove script dir: SlurmPool . clean () Custom the job Pool: p = SlurmPool ( pool_size = None , #how many jobs run in parallel, use all resources if not specify. ncpus_per_job = 2 , #how many cpus per job use max_jobs_per_node = None , #how many jobs can a node run at most node_list = None # use all nodes if not specify )","title":"submit multiple job"},{"location":"usage/#usage-for-cli-tool","text":"","title":"Usage for CLI tool"},{"location":"usage/#help-message","text":"$ autosbatch --help Usage: autosbatch [ OPTIONS ] COMMAND [ ARGS ] ... Submit jobs to slurm cluster, without writing slurm script files. \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --version -V Show version. \u2502 \u2502 --verbose -v Show verbose info. \u2502 \u2502 --dev Show dev info. \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 clean Remove all scripts and logs. \u2502 \u2502 multi-job Submit multiple jobs to slurm cluster. \u2502 \u2502 single-job Submit a single job to slurm cluster. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f","title":"help message"},{"location":"usage/#command-single-job","text":"$ autosbatch single-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch single-job [ OPTIONS ] CMD... Submit a single job to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmd CMD... Command to run. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --ncpus -n INTEGER Number of cpus. [ default: 1 ] \u2502 \u2502 --node -N TEXT Node to submit job to. [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs to. [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. [ default: job ] \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f run example command such as sleep 10 autosbatch single-job sleep 10 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :13:46 ] WARNING Hyperthreading is enabled on cpu14, ncpus_per_job is set to 2 .","title":"Command: single-job"},{"location":"usage/#command-multi-job","text":"$ autosbatch multi-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch multi-job [ OPTIONS ] CMDFILE Submit multiple jobs to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmdfile PATH Path to the command file. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --pool-size -p INTEGER RANGE Number of jobs to submit \u2502 \u2502 [ 0 < = x< = 1000 ] at the same time. \u2502 \u2502 [ default: None ] \u2502 \u2502 --ncpus-per-job -n INTEGER Number of cpus per job. \u2502 \u2502 [ default: 1 ] \u2502 \u2502 --max-jobs-per-node -m INTEGER Maximum number of jobs \u2502 \u2502 to submit to a single \u2502 \u2502 node. \u2502 \u2502 [ default: None ] \u2502 \u2502 --node-list -l TEXT List of nodes to submit \u2502 \u2502 jobs to. e.g. \"-l node1 \u2502 \u2502 -l node2 -l node3\" \u2502 \u2502 [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs \u2502 \u2502 to. \u2502 \u2502 [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. \u2502 \u2502 [ default: job ] \u2502 \u2502 --help -h Show this message and \u2502 \u2502 exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f submit 10 commands to slurm Step1. write the commands into a text file, one command per line. $ cat ./cmd.sh sleep 0 sleep 1 sleep 2 sleep 3 sleep 4 sleep 5 sleep 6 sleep 7 sleep 8 sleep 9 Step2 run multi-job command $ autosbatch multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00","title":"Command: multi-job"},{"location":"usage/#command-clean","text":"remove the directory contains scripts and logs autosbatch clean","title":"Command: clean"},{"location":"usage/#enable-verbose","text":"add -v or --verbose between autosbatch and command e.g.: $ autosbatch -v multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :21:44 ] INFO Verbose mode is on. INFO Found 2 available nodes. INFO 10 jobs to excute, allocated to 6 tasks. INFO Each task will use 1 cpus. INFO Used 2 nodes. INFO Each node will excute 3 tasks in parallel. INFO { 'gpu02' : 3 , 'gpu03' : 3 } INFO gpu02: 3 tasks INFO Task 0 : containing job 0 -1 INFO Sumbitted Task: job_000 to gpu02, containing 2 jobs. Slurm ID: 254554 [ 22 :21:45 ] INFO Task 1 : containing job 2 -3 INFO Sumbitted Task: job_001 to gpu02, containing 2 jobs. Slurm ID: 254555 INFO Task 2 : containing job 4 -5 [ 22 :21:46 ] INFO Sumbitted Task: job_002 to gpu02, containing 2 jobs. Slurm ID: 254556 INFO gpu03: 3 tasks INFO Task 3 : containing job 6 -7 INFO Sumbitted Task: job_003 to gpu03, containing 2 jobs. Slurm ID: 254557 [ 22 :21:47 ] INFO Task 4 : containing job 8 -8 INFO Sumbitted Task: job_004 to gpu03, containing 1 jobs. Slurm ID: 254558 INFO Task 5 : containing job 9 -9 INFO Sumbitted Task: job_005 to gpu03, containing 1 jobs. Slurm ID: 254559 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 INFO Writing task log to .autosbatch/1219222144/1219222144.log","title":"enable verbose"}]}