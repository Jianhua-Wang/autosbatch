{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"autosbatch \u00b6 submit hundreds of jobs to slurm automatically Documentation: https://Jianhua-Wang.github.io/autosbatch GitHub: https://github.com/Jianhua-Wang/autosbatch PyPI: https://pypi.org/project/autosbatch/ Free software: MIT Features \u00b6 Sometimes, it's quite inconvenient when we submit hundreds of jobs to slurm. For example, one needs to align RNA-seq data from one hundred samples. He may start with a bash script that takes the fastq of one sample and write sbatch scripts which execute bash align.sh sample.fq multiple times. If he wants to run 50 samples at the same time, he should write 50 sbatch scripts and each script contains two align commands. Manually managing these sbatch scripts is inconvenient. autosbatch is very helpful for submitting slurm jobs automatically and it's just like the multiprocessing.Pool . Automatically submit hundreds of jobs to Slurm with a few code. The same usage as multiprocessing.Pool . Provide command line tool for people who are not familiar with Python. TODO \u00b6 Support gpu allocation Support MPI jobs Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Home"},{"location":"#autosbatch","text":"submit hundreds of jobs to slurm automatically Documentation: https://Jianhua-Wang.github.io/autosbatch GitHub: https://github.com/Jianhua-Wang/autosbatch PyPI: https://pypi.org/project/autosbatch/ Free software: MIT","title":"autosbatch"},{"location":"#features","text":"Sometimes, it's quite inconvenient when we submit hundreds of jobs to slurm. For example, one needs to align RNA-seq data from one hundred samples. He may start with a bash script that takes the fastq of one sample and write sbatch scripts which execute bash align.sh sample.fq multiple times. If he wants to run 50 samples at the same time, he should write 50 sbatch scripts and each script contains two align commands. Manually managing these sbatch scripts is inconvenient. autosbatch is very helpful for submitting slurm jobs automatically and it's just like the multiprocessing.Pool . Automatically submit hundreds of jobs to Slurm with a few code. The same usage as multiprocessing.Pool . Provide command line tool for people who are not familiar with Python.","title":"Features"},{"location":"#todo","text":"Support gpu allocation Support MPI jobs","title":"TODO"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"A class for submitting jobs to Slurm. Parameters: Name Type Description Default pool_size int , optional Number of jobs to submit at the same time, by default None None ncpus_per_job int , optional Number of cpus per job, by default 1 1 max_jobs_per_node int , optional Maximum number of jobs to submit to a single node, by default None None node_list List [ str ], optional List of nodes to submit jobs to, by default None None partition str , optional Partition to submit jobs to, by default None None max_pool_size int , optional Maximum number of jobs to submit, by default 1000 1000 Source code in autosbatch/autosbatch.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def __init__ ( self , pool_size : Optional [ int ] = None , ncpus_per_job : int = 1 , max_jobs_per_node : Optional [ int ] = None , node_list : Optional [ List [ str ]] = None , partition : Optional [ str ] = None , max_pool_size : int = 1000 , ): \"\"\" Initialize a SlurmPool object. Parameters ---------- pool_size : int, optional Number of jobs to submit at the same time, by default None ncpus_per_job : int, optional Number of cpus per job, by default 1 max_jobs_per_node : int, optional Maximum number of jobs to submit to a single node, by default None node_list : List[str], optional List of nodes to submit jobs to, by default None partition : str, optional Partition to submit jobs to, by default None max_pool_size : int, optional Maximum number of jobs to submit, by default 1000 \"\"\" self . ncpus_per_job = ncpus_per_job self . nodes = self . get_nodes () self . _get_avail_nodes ( node_list = node_list , partition = partition ) self . node_list = list ( self . nodes . keys ()) if len ( self . node_list ) == 0 : raise RuntimeError ( 'No Nodes are qualtified.' ) self . _set_max_jobs_per_node ( max_jobs_per_node = max_jobs_per_node ) jobs_on_nodes = { k : v [ 'max_jobs' ] for k , v in self . nodes . items ()} self . jobs_on_nodes = { k : v if v <= self . max_jobs_per_node else self . max_jobs_per_node for k , v in jobs_on_nodes . items () } self . _set_pool_size ( pool_size = pool_size , max_pool_size = max_pool_size ) self . time_now = datetime . datetime . now () . strftime ( '%m %d %H%M%S' ) self . file_dir = f ' { self . dir_path } / { self . time_now } ' self . log_dir = f ' { self . file_dir } /log' self . scripts_dir = f ' { self . file_dir } /scripts' __enter__ () \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 423 424 425 def __enter__ ( self ): \"\"\"Clean up the scripts and log files.\"\"\" return self __exit__ ( exc_type , exc_val , exc_tb ) \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 427 428 429 def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\"Clean up the scripts and log files.\"\"\" self . close () clean () classmethod \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 413 414 415 416 417 @classmethod def clean ( cls ): \"\"\"Clean up the scripts and log files.\"\"\" command = [ 'rm' , '-rf' , cls . dir_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) close () \u00b6 Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 419 420 421 def close ( self ): \"\"\"Clean up the scripts and log files.\"\"\" pass get_nodes ( sortByload = True ) classmethod \u00b6 Get nodes information from sinfo. Parameters: Name Type Description Default sortByload bool , optional Sort nodes by load, by default True True Returns: Type Description Dict Information of nodes, by default Source code in autosbatch/autosbatch.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @classmethod def get_nodes ( cls , sortByload = True ) -> Dict : \"\"\" Get nodes information from sinfo. Parameters ---------- sortByload : bool, optional Sort nodes by load, by default True Returns ------- Dict Information of nodes, by default \"\"\" command = [ 'sinfo' , '-o' , '\"%n %e %m %a %c %C %O %R %t\"' ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) nodes = {} for line in result . stdout . splitlines (): line = line . strip ( ' \\\" ' ) if line . startswith ( 'HOSTNAMES' ): continue node , free_mem , memory , avail , cpus , free_cpus , load , partition , state = line . split () nodes [ node ] = { 'free_mem' : int ( free_mem ), 'used_mem' : int ( memory ) - int ( free_mem ), 'memory' : int ( memory ), 'AVAIL' : avail , 'cpus' : int ( cpus ), 'used_cpus' : int ( free_cpus . split ( '/' )[ 0 ]), 'free_cpus' : int ( free_cpus . split ( '/' )[ 1 ]), 'load' : float ( load ), 'partition' : partition , 'state' : state , } if sortByload : nodes = dict ( OrderedDict ( sorted ( nodes . items (), key = lambda x : ( x [ 1 ][ 'load' ], x [ 1 ][ 'used_mem' ], x [ 1 ][ 'used_cpus' ]))) ) return nodes map ( func , params ) \u00b6 Submit a list of commands to the cluster. Parameters: Name Type Description Default func Callable Function to call required params Iterable Parameters to pass to the function required Returns: Type Description None Source code in autosbatch/autosbatch.py 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 def map ( self , func : Callable , params : Iterable ): \"\"\" Submit a list of commands to the cluster. Parameters ---------- func : Callable Function to call params : Iterable Parameters to pass to the function Returns ------- None \"\"\" cmds = [ func ( i ) for i in params ] self . multi_submit ( cmds , func . __name__ ) multi_submit ( cmds , job_name , shuffle = False , sleep_time = 0.5 ) \u00b6 Submit jobs to multiple nodes. Parameters: Name Type Description Default cmds List [ str ] Commands to run required job_name str Name of the job required logging_level int , optional Logging level, by default logging.WARNING required shuffle bool , optional Shuffle the commands, by default False False sleep_time float , optional Time to sleep between each submission, by default 0.5 0.5 Returns: Type Description None Source code in autosbatch/autosbatch.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 def multi_submit ( self , cmds : List [ str ], job_name : str , # logging_level: int = logging.WARNING, shuffle : bool = False , sleep_time : float = 0.5 , ): \"\"\" Submit jobs to multiple nodes. Parameters ---------- cmds : List[str] Commands to run job_name : str Name of the job logging_level : int, optional Logging level, by default logging.WARNING shuffle : bool, optional Shuffle the commands, by default False sleep_time : float, optional Time to sleep between each submission, by default 0.5 Returns ------- None \"\"\" if shuffle : import random random . shuffle ( cmds ) # logger.setLevel(logging_level) logger . info ( f 'Found { len ( self . nodes ) } available nodes.' ) self . pool_size = min ( self . pool_size , len ( cmds )) logger . info ( f ' { len ( cmds ) : , } jobs to excute, allocated to { self . pool_size } tasks.' ) logger . info ( f 'Each task will use { self . ncpus_per_job } cpus.' ) used_nodes = {} registed_jobs = 0 for k , v in self . jobs_on_nodes . items (): used_nodes [ k ] = v registed_jobs += v if registed_jobs < self . pool_size : continue elif registed_jobs == self . pool_size : break else : used_nodes [ k ] -= registed_jobs - self . pool_size break logger . info ( f 'Used { len ( used_nodes ) } nodes.' ) logger . info ( f 'Each node will excute { max ( used_nodes . values ()) } tasks in parallel.' ) logger . info ( f ' { used_nodes } ' ) k , m = divmod ( len ( cmds ), self . pool_size ) ith = 0 task_log = {} with Progress ( TextColumn ( \" {task.description} \" ), BarColumn (), MofNCompleteColumn (), TimeRemainingColumn (), auto_refresh = False , ) as progress : for node , n_jobs in used_nodes . items (): logger . info ( f ' { node } : { n_jobs } tasks' ) task = progress . add_task ( f \"Submitting to { node } ...\" , total = n_jobs ) for _ in range ( n_jobs ): time . sleep ( sleep_time ) start , end = ith * k + min ( ith , m ), ( ith + 1 ) * k + min ( ith + 1 , m ) logger . info ( f 'Task { ith } : containing job { start } - { end - 1 } ' ) task_name = f ' { job_name } _ { ith : >03 } ' self . single_submit ( self . nodes [ node ][ 'partition' ], node , self . ncpus_per_job , cmds [ start : end ], task_name , # logging_level, ) progress . update ( task , advance = 1 ) progress . refresh () ith += 1 task_log [ task_name ] = { 'node' : node , 'script' : f ' { task_name } .sh' , 'stdout' : f ' { task_name } .out.log' , 'stderr' : f ' { task_name } .err.log' , 'cmd' : cmds [ start : end ], } with open ( f ' { self . file_dir } / { self . time_now } .log' , 'w' ) as f : logger . info ( f 'Writing task log to { self . file_dir } / { self . time_now } .log' ) json . dump ( task_log , f , indent = 4 ) single_submit ( partition , node , cpus_per_task , cmds , job_name = 'job' ) \u00b6 Submit a single job. Parameters: Name Type Description Default partition str Partition to submit jobs to required node str Node to submit jobs to required cpus_per_task int Number of CPUs to use required cmds str or List[str] Commands to run required job_name str , optional Name of the job, by default 'job' 'job' logging_level int , optional Logging level, by default logging.WARNING required Returns: Type Description None Source code in autosbatch/autosbatch.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 def single_submit ( self , partition : str , node : str , cpus_per_task : int , cmds : Union [ str , List [ str ]], job_name : str = 'job' , # logging_level: int = logging.WARNING, ): \"\"\" Submit a single job. Parameters ---------- partition : str Partition to submit jobs to node : str Node to submit jobs to cpus_per_task : int Number of CPUs to use cmds : str or List[str] Commands to run job_name : str, optional Name of the job, by default 'job' logging_level : int, optional Logging level, by default logging.WARNING Returns ------- None \"\"\" # logger.setLevel(logging_level) Path ( self . scripts_dir ) . mkdir ( parents = True , exist_ok = True ) Path ( self . log_dir ) . mkdir ( parents = True , exist_ok = True ) templateLoader = FileSystemLoader ( searchpath = f \" { os . path . dirname ( os . path . realpath ( __file__ )) } /template\" ) env = Environment ( loader = templateLoader ) template = env . get_template ( self . CPU_OpenMP_TEMPLATE ) if isinstance ( cmds , str ): cmds = [ cmds ] output_from_parsed_template = template . render ( job_name = job_name , partition = partition , node = node , cpus_per_task = cpus_per_task , cmds = ' \\n ' . join ( cmds ), log_dir = self . log_dir , ) script_path = f ' { self . scripts_dir } / { job_name } .sh' with open ( script_path , 'w' ) as f : f . write ( output_from_parsed_template ) command = [ 'chmod' , '755' , script_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) command = [ 'sbatch' , script_path ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) slurm_id = result . stdout . strip () . split ()[ - 1 ] logger . info ( f 'Sumbitted Task: { job_name } to { node } , containing { len ( cmds ) } jobs. Slurm ID: { slurm_id } ' ) logger . debug ( f 'Commands: { cmds } ' ) starmap ( func , params ) \u00b6 Submit a list of commands to the cluster. Parameters: Name Type Description Default func Callable Function to call required params Iterable [ Iterable ] Parameters to pass to the function required Returns: Type Description None Source code in autosbatch/autosbatch.py 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 def starmap ( self , func : Callable , params : Iterable [ Iterable ]): \"\"\" Submit a list of commands to the cluster. Parameters ---------- func : Callable Function to call params : Iterable[Iterable] Parameters to pass to the function Returns ------- None \"\"\" cmds = [ func ( * i ) for i in params ] self . multi_submit ( cmds , func . __name__ )","title":"Modules"},{"location":"api/#autosbatch.autosbatch.SlurmPool.__enter__","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 423 424 425 def __enter__ ( self ): \"\"\"Clean up the scripts and log files.\"\"\" return self","title":"__enter__()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.__exit__","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 427 428 429 def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\"Clean up the scripts and log files.\"\"\" self . close ()","title":"__exit__()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.clean","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 413 414 415 416 417 @classmethod def clean ( cls ): \"\"\"Clean up the scripts and log files.\"\"\" command = [ 'rm' , '-rf' , cls . dir_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True )","title":"clean()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.close","text":"Clean up the scripts and log files. Source code in autosbatch/autosbatch.py 419 420 421 def close ( self ): \"\"\"Clean up the scripts and log files.\"\"\" pass","title":"close()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.get_nodes","text":"Get nodes information from sinfo. Parameters: Name Type Description Default sortByload bool , optional Sort nodes by load, by default True True Returns: Type Description Dict Information of nodes, by default Source code in autosbatch/autosbatch.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @classmethod def get_nodes ( cls , sortByload = True ) -> Dict : \"\"\" Get nodes information from sinfo. Parameters ---------- sortByload : bool, optional Sort nodes by load, by default True Returns ------- Dict Information of nodes, by default \"\"\" command = [ 'sinfo' , '-o' , '\"%n %e %m %a %c %C %O %R %t\"' ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) nodes = {} for line in result . stdout . splitlines (): line = line . strip ( ' \\\" ' ) if line . startswith ( 'HOSTNAMES' ): continue node , free_mem , memory , avail , cpus , free_cpus , load , partition , state = line . split () nodes [ node ] = { 'free_mem' : int ( free_mem ), 'used_mem' : int ( memory ) - int ( free_mem ), 'memory' : int ( memory ), 'AVAIL' : avail , 'cpus' : int ( cpus ), 'used_cpus' : int ( free_cpus . split ( '/' )[ 0 ]), 'free_cpus' : int ( free_cpus . split ( '/' )[ 1 ]), 'load' : float ( load ), 'partition' : partition , 'state' : state , } if sortByload : nodes = dict ( OrderedDict ( sorted ( nodes . items (), key = lambda x : ( x [ 1 ][ 'load' ], x [ 1 ][ 'used_mem' ], x [ 1 ][ 'used_cpus' ]))) ) return nodes","title":"get_nodes()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.map","text":"Submit a list of commands to the cluster. Parameters: Name Type Description Default func Callable Function to call required params Iterable Parameters to pass to the function required Returns: Type Description None Source code in autosbatch/autosbatch.py 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 def map ( self , func : Callable , params : Iterable ): \"\"\" Submit a list of commands to the cluster. Parameters ---------- func : Callable Function to call params : Iterable Parameters to pass to the function Returns ------- None \"\"\" cmds = [ func ( i ) for i in params ] self . multi_submit ( cmds , func . __name__ )","title":"map()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.multi_submit","text":"Submit jobs to multiple nodes. Parameters: Name Type Description Default cmds List [ str ] Commands to run required job_name str Name of the job required logging_level int , optional Logging level, by default logging.WARNING required shuffle bool , optional Shuffle the commands, by default False False sleep_time float , optional Time to sleep between each submission, by default 0.5 0.5 Returns: Type Description None Source code in autosbatch/autosbatch.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 def multi_submit ( self , cmds : List [ str ], job_name : str , # logging_level: int = logging.WARNING, shuffle : bool = False , sleep_time : float = 0.5 , ): \"\"\" Submit jobs to multiple nodes. Parameters ---------- cmds : List[str] Commands to run job_name : str Name of the job logging_level : int, optional Logging level, by default logging.WARNING shuffle : bool, optional Shuffle the commands, by default False sleep_time : float, optional Time to sleep between each submission, by default 0.5 Returns ------- None \"\"\" if shuffle : import random random . shuffle ( cmds ) # logger.setLevel(logging_level) logger . info ( f 'Found { len ( self . nodes ) } available nodes.' ) self . pool_size = min ( self . pool_size , len ( cmds )) logger . info ( f ' { len ( cmds ) : , } jobs to excute, allocated to { self . pool_size } tasks.' ) logger . info ( f 'Each task will use { self . ncpus_per_job } cpus.' ) used_nodes = {} registed_jobs = 0 for k , v in self . jobs_on_nodes . items (): used_nodes [ k ] = v registed_jobs += v if registed_jobs < self . pool_size : continue elif registed_jobs == self . pool_size : break else : used_nodes [ k ] -= registed_jobs - self . pool_size break logger . info ( f 'Used { len ( used_nodes ) } nodes.' ) logger . info ( f 'Each node will excute { max ( used_nodes . values ()) } tasks in parallel.' ) logger . info ( f ' { used_nodes } ' ) k , m = divmod ( len ( cmds ), self . pool_size ) ith = 0 task_log = {} with Progress ( TextColumn ( \" {task.description} \" ), BarColumn (), MofNCompleteColumn (), TimeRemainingColumn (), auto_refresh = False , ) as progress : for node , n_jobs in used_nodes . items (): logger . info ( f ' { node } : { n_jobs } tasks' ) task = progress . add_task ( f \"Submitting to { node } ...\" , total = n_jobs ) for _ in range ( n_jobs ): time . sleep ( sleep_time ) start , end = ith * k + min ( ith , m ), ( ith + 1 ) * k + min ( ith + 1 , m ) logger . info ( f 'Task { ith } : containing job { start } - { end - 1 } ' ) task_name = f ' { job_name } _ { ith : >03 } ' self . single_submit ( self . nodes [ node ][ 'partition' ], node , self . ncpus_per_job , cmds [ start : end ], task_name , # logging_level, ) progress . update ( task , advance = 1 ) progress . refresh () ith += 1 task_log [ task_name ] = { 'node' : node , 'script' : f ' { task_name } .sh' , 'stdout' : f ' { task_name } .out.log' , 'stderr' : f ' { task_name } .err.log' , 'cmd' : cmds [ start : end ], } with open ( f ' { self . file_dir } / { self . time_now } .log' , 'w' ) as f : logger . info ( f 'Writing task log to { self . file_dir } / { self . time_now } .log' ) json . dump ( task_log , f , indent = 4 )","title":"multi_submit()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.single_submit","text":"Submit a single job. Parameters: Name Type Description Default partition str Partition to submit jobs to required node str Node to submit jobs to required cpus_per_task int Number of CPUs to use required cmds str or List[str] Commands to run required job_name str , optional Name of the job, by default 'job' 'job' logging_level int , optional Logging level, by default logging.WARNING required Returns: Type Description None Source code in autosbatch/autosbatch.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 def single_submit ( self , partition : str , node : str , cpus_per_task : int , cmds : Union [ str , List [ str ]], job_name : str = 'job' , # logging_level: int = logging.WARNING, ): \"\"\" Submit a single job. Parameters ---------- partition : str Partition to submit jobs to node : str Node to submit jobs to cpus_per_task : int Number of CPUs to use cmds : str or List[str] Commands to run job_name : str, optional Name of the job, by default 'job' logging_level : int, optional Logging level, by default logging.WARNING Returns ------- None \"\"\" # logger.setLevel(logging_level) Path ( self . scripts_dir ) . mkdir ( parents = True , exist_ok = True ) Path ( self . log_dir ) . mkdir ( parents = True , exist_ok = True ) templateLoader = FileSystemLoader ( searchpath = f \" { os . path . dirname ( os . path . realpath ( __file__ )) } /template\" ) env = Environment ( loader = templateLoader ) template = env . get_template ( self . CPU_OpenMP_TEMPLATE ) if isinstance ( cmds , str ): cmds = [ cmds ] output_from_parsed_template = template . render ( job_name = job_name , partition = partition , node = node , cpus_per_task = cpus_per_task , cmds = ' \\n ' . join ( cmds ), log_dir = self . log_dir , ) script_path = f ' { self . scripts_dir } / { job_name } .sh' with open ( script_path , 'w' ) as f : f . write ( output_from_parsed_template ) command = [ 'chmod' , '755' , script_path ] _ = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) command = [ 'sbatch' , script_path ] result = run ( command , stdout = PIPE , stderr = PIPE , universal_newlines = True ) slurm_id = result . stdout . strip () . split ()[ - 1 ] logger . info ( f 'Sumbitted Task: { job_name } to { node } , containing { len ( cmds ) } jobs. Slurm ID: { slurm_id } ' ) logger . debug ( f 'Commands: { cmds } ' )","title":"single_submit()"},{"location":"api/#autosbatch.autosbatch.SlurmPool.starmap","text":"Submit a list of commands to the cluster. Parameters: Name Type Description Default func Callable Function to call required params Iterable [ Iterable ] Parameters to pass to the function required Returns: Type Description None Source code in autosbatch/autosbatch.py 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 def starmap ( self , func : Callable , params : Iterable [ Iterable ]): \"\"\" Submit a list of commands to the cluster. Parameters ---------- func : Callable Function to call params : Iterable[Iterable] Parameters to pass to the function Returns ------- None \"\"\" cmds = [ func ( * i ) for i in params ] self . multi_submit ( cmds , func . __name__ )","title":"starmap()"},{"location":"changelog/","text":"Changelog \u00b6 [0.2.0] - 2023-03-01 \u00b6 Added \u00b6 Changed \u00b6 change log level to info Fixed \u00b6 [0.1.9] - 2023-02-08 \u00b6 Added \u00b6 Changed \u00b6 change log file dir to init Fixed \u00b6 log file directory is class atribute [0.1.8] - 2022-12-19 \u00b6 Added \u00b6 add api docs Changed \u00b6 Fixed \u00b6 [0.1.7] - 2022-12-19 \u00b6 Added \u00b6 Changed \u00b6 disable auto_refresh progress bar Fixed \u00b6 [0.1.0] - 2022-12-16 \u00b6 Here we would have the update steps for 1.2.4 for people to follow. Added \u00b6 Changed \u00b6 PROJECTNAME-ZZZZ PATCH Drupal.org is now used for composer. Fixed \u00b6 PROJECTNAME-TTTT PATCH Add logic to runsheet teaser delete to delete corresponding schedule cards. [0.1.1] - 2022-12-16 \u00b6 Added \u00b6 Changed \u00b6 Fixed \u00b6 PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution [0.1.2] - 2022-12-16 \u00b6 Added \u00b6 Changed \u00b6 Fixed \u00b6 PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution [0.1.3] - 2022-12-17 \u00b6 Added \u00b6 Changed \u00b6 Reconstruct the project structure Fixed \u00b6 [0.1.4] - 2022-12-18 \u00b6 Added \u00b6 Changed \u00b6 Use jinja2 as sbatch template change script dir to .autosbatch get rid of pandas replace call with subprocess.run speed up by remove append Add a logger save job information to a file Fixed \u00b6 [0.1.5] - 2022-12-19 \u00b6 Added \u00b6 clean command multi submit command single submit command Changed \u00b6 replace click with typer Fixed \u00b6 [0.1.6] - 2022-12-19 \u00b6 Added \u00b6 support context manager add docs Changed \u00b6 Fixed \u00b6","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#020-2023-03-01","text":"","title":"[0.2.0] - 2023-03-01"},{"location":"changelog/#added","text":"","title":"Added"},{"location":"changelog/#changed","text":"change log level to info","title":"Changed"},{"location":"changelog/#fixed","text":"","title":"Fixed"},{"location":"changelog/#019-2023-02-08","text":"","title":"[0.1.9] - 2023-02-08"},{"location":"changelog/#added_1","text":"","title":"Added"},{"location":"changelog/#changed_1","text":"change log file dir to init","title":"Changed"},{"location":"changelog/#fixed_1","text":"log file directory is class atribute","title":"Fixed"},{"location":"changelog/#018-2022-12-19","text":"","title":"[0.1.8] - 2022-12-19"},{"location":"changelog/#added_2","text":"add api docs","title":"Added"},{"location":"changelog/#changed_2","text":"","title":"Changed"},{"location":"changelog/#fixed_2","text":"","title":"Fixed"},{"location":"changelog/#017-2022-12-19","text":"","title":"[0.1.7] - 2022-12-19"},{"location":"changelog/#added_3","text":"","title":"Added"},{"location":"changelog/#changed_3","text":"disable auto_refresh progress bar","title":"Changed"},{"location":"changelog/#fixed_3","text":"","title":"Fixed"},{"location":"changelog/#010-2022-12-16","text":"Here we would have the update steps for 1.2.4 for people to follow.","title":"[0.1.0] - 2022-12-16"},{"location":"changelog/#added_4","text":"","title":"Added"},{"location":"changelog/#changed_4","text":"PROJECTNAME-ZZZZ PATCH Drupal.org is now used for composer.","title":"Changed"},{"location":"changelog/#fixed_4","text":"PROJECTNAME-TTTT PATCH Add logic to runsheet teaser delete to delete corresponding schedule cards.","title":"Fixed"},{"location":"changelog/#011-2022-12-16","text":"","title":"[0.1.1] - 2022-12-16"},{"location":"changelog/#added_5","text":"","title":"Added"},{"location":"changelog/#changed_5","text":"","title":"Changed"},{"location":"changelog/#fixed_5","text":"PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution","title":"Fixed"},{"location":"changelog/#012-2022-12-16","text":"","title":"[0.1.2] - 2022-12-16"},{"location":"changelog/#added_6","text":"","title":"Added"},{"location":"changelog/#changed_6","text":"","title":"Changed"},{"location":"changelog/#fixed_6","text":"PROJECTNAME-UUUU MINOR Fix module foo tests PROJECTNAME-RRRR MAJOR Module foo's timeline uses the browser timezone for date resolution","title":"Fixed"},{"location":"changelog/#013-2022-12-17","text":"","title":"[0.1.3] - 2022-12-17"},{"location":"changelog/#added_7","text":"","title":"Added"},{"location":"changelog/#changed_7","text":"Reconstruct the project structure","title":"Changed"},{"location":"changelog/#fixed_7","text":"","title":"Fixed"},{"location":"changelog/#014-2022-12-18","text":"","title":"[0.1.4] - 2022-12-18"},{"location":"changelog/#added_8","text":"","title":"Added"},{"location":"changelog/#changed_8","text":"Use jinja2 as sbatch template change script dir to .autosbatch get rid of pandas replace call with subprocess.run speed up by remove append Add a logger save job information to a file","title":"Changed"},{"location":"changelog/#fixed_8","text":"","title":"Fixed"},{"location":"changelog/#015-2022-12-19","text":"","title":"[0.1.5] - 2022-12-19"},{"location":"changelog/#added_9","text":"clean command multi submit command single submit command","title":"Added"},{"location":"changelog/#changed_9","text":"replace click with typer","title":"Changed"},{"location":"changelog/#fixed_9","text":"","title":"Fixed"},{"location":"changelog/#016-2022-12-19","text":"","title":"[0.1.6] - 2022-12-19"},{"location":"changelog/#added_10","text":"support context manager add docs","title":"Added"},{"location":"changelog/#changed_10","text":"","title":"Changed"},{"location":"changelog/#fixed_10","text":"","title":"Fixed"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/Jianhua-Wang/autosbatch/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 autosbatch could always use more documentation, whether as part of the official autosbatch docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/Jianhua-Wang/autosbatch/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up autosbatch for local development. Fork the autosbatch repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/autosbatch.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/Jianhua-Wang/autosbatch/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 $ poetry run pytest tests/test_autosbatch.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/Jianhua-Wang/autosbatch/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"autosbatch could always use more documentation, whether as part of the official autosbatch docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/Jianhua-Wang/autosbatch/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up autosbatch for local development. Fork the autosbatch repo on GitHub. Clone your fork locally $ git clone git@github.com:your_name_here/autosbatch.git Ensure poetry is installed. Install dependencies and start your virtualenv: $ poetry install -E test -E doc -E dev Create a branch for local development: $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: $ poetry run tox Commit your changes and push your branch to GitHub: $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/Jianhua-Wang/autosbatch/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"$ poetry run pytest tests/test_autosbatch.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install autosbatch, run this command in your terminal: $ pip install autosbatch This is the preferred method to install autosbatch, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for autosbatch can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/Jianhua-Wang/autosbatch Or download the tarball : $ curl -OJL https://github.com/Jianhua-Wang/autosbatch/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install autosbatch, run this command in your terminal: $ pip install autosbatch This is the preferred method to install autosbatch, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for autosbatch can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/Jianhua-Wang/autosbatch Or download the tarball : $ curl -OJL https://github.com/Jianhua-Wang/autosbatch/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 Usage for package \u00b6 Import \u00b6 import autosbatch # or import SlurmPool directly from autosbatch import SlurmPool submit single job \u00b6 run sleep 10 on node cpu01 on cpuPartition paritition. SlurmPool () . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = 'sleep 10' , job_name = 'test' , job_id = '001' ) or run a job containing two steps, e.g. echo hello and sleep 10 SlurmPool () . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = [ 'echo hello' , 'sleep 10' ], job_name = 'test' , job_id = '001' ) submit multiple job \u00b6 TODO: compare multiprocessing.Pool.map TODO: add with syntax Just like multiprocessing.Pool.map # construct the excutor def sleep ( time ): cmd = f 'sleep { time } ' return cmd # prepare the param for each excutor params = range ( 10 ) # submit to parallel run p = SlurmPool ( 10 ) p . map ( sleep , params ) multiple parameters (similar with multiprocessing.Pool.starmap ) # construct the excutor def echo_sleep ( text , time ): cmd = f 'echo { text } && sleep { time } ' return cmd # prepare the params for each excutor params = [] for text in range ( 5 ): for time in range ( 6 ): params . append ([ text , time ]) # submit to parallel run p = SlurmPool ( 10 ) p . starmap ( echo_sleep , params ) The sbatch scripts are put in ./autosbatch/$timenow/script . The error and stdout logs are in ./autosbatch/$timenow/log . remove script dir: SlurmPool . clean () Custom the job Pool: p = SlurmPool ( pool_size = None , #how many jobs run in parallel, use all resources if not specify. ncpus_per_job = 2 , #how many cpus per job use max_jobs_per_node = None , #how many jobs can a node run at most node_list = None # use all nodes if not specify ) Usage for CLI tool \u00b6 help message \u00b6 $ autosbatch --help Usage: autosbatch [ OPTIONS ] COMMAND [ ARGS ] ... Submit jobs to slurm cluster, without writing slurm script files. \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --version -V Show version. \u2502 \u2502 --verbose -v Show verbose info. \u2502 \u2502 --dev Show dev info. \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 clean Remove all scripts and logs. \u2502 \u2502 multi-job Submit multiple jobs to slurm cluster. \u2502 \u2502 single-job Submit a single job to slurm cluster. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f Command: single-job \u00b6 $ autosbatch single-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch single-job [ OPTIONS ] CMD... Submit a single job to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmd CMD... Command to run. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --ncpus -n INTEGER Number of cpus. [ default: 1 ] \u2502 \u2502 --node -N TEXT Node to submit job to. [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs to. [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. [ default: job ] \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f run example command such as sleep 10 autosbatch single-job sleep 10 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :13:46 ] WARNING Hyperthreading is enabled on cpu14, ncpus_per_job is set to 2 . Command: multi-job \u00b6 $ autosbatch multi-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch multi-job [ OPTIONS ] CMDFILE Submit multiple jobs to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmdfile PATH Path to the command file. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --pool-size -p INTEGER RANGE Number of jobs to submit \u2502 \u2502 [ 0 < = x< = 1000 ] at the same time. \u2502 \u2502 [ default: None ] \u2502 \u2502 --ncpus-per-job -n INTEGER Number of cpus per job. \u2502 \u2502 [ default: 1 ] \u2502 \u2502 --max-jobs-per-node -m INTEGER Maximum number of jobs \u2502 \u2502 to submit to a single \u2502 \u2502 node. \u2502 \u2502 [ default: None ] \u2502 \u2502 --node-list -l TEXT List of nodes to submit \u2502 \u2502 jobs to. e.g. \"-l node1 \u2502 \u2502 -l node2 -l node3\" \u2502 \u2502 [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs \u2502 \u2502 to. \u2502 \u2502 [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. \u2502 \u2502 [ default: job ] \u2502 \u2502 --help -h Show this message and \u2502 \u2502 exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f submit 10 commands to slurm Step1. write the commands into a text file, one command per line. $ cat ./cmd.sh sleep 0 sleep 1 sleep 2 sleep 3 sleep 4 sleep 5 sleep 6 sleep 7 sleep 8 sleep 9 Step2 run multi-job command $ autosbatch multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Command: clean \u00b6 remove the directory contains scripts and logs autosbatch clean enable verbose \u00b6 add -v or --verbose between autosbatch and command e.g.: $ autosbatch -v multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :21:44 ] INFO Verbose mode is on. INFO Found 2 available nodes. INFO 10 jobs to excute, allocated to 6 tasks. INFO Each task will use 1 cpus. INFO Used 2 nodes. INFO Each node will excute 3 tasks in parallel. INFO { 'gpu02' : 3 , 'gpu03' : 3 } INFO gpu02: 3 tasks INFO Task 0 : containing job 0 -1 INFO Sumbitted Task: job_000 to gpu02, containing 2 jobs. Slurm ID: 254554 [ 22 :21:45 ] INFO Task 1 : containing job 2 -3 INFO Sumbitted Task: job_001 to gpu02, containing 2 jobs. Slurm ID: 254555 INFO Task 2 : containing job 4 -5 [ 22 :21:46 ] INFO Sumbitted Task: job_002 to gpu02, containing 2 jobs. Slurm ID: 254556 INFO gpu03: 3 tasks INFO Task 3 : containing job 6 -7 INFO Sumbitted Task: job_003 to gpu03, containing 2 jobs. Slurm ID: 254557 [ 22 :21:47 ] INFO Task 4 : containing job 8 -8 INFO Sumbitted Task: job_004 to gpu03, containing 1 jobs. Slurm ID: 254558 INFO Task 5 : containing job 9 -9 INFO Sumbitted Task: job_005 to gpu03, containing 1 jobs. Slurm ID: 254559 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 INFO Writing task log to .autosbatch/1219222144/1219222144.log","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#usage-for-package","text":"","title":"Usage for package"},{"location":"usage/#import","text":"import autosbatch # or import SlurmPool directly from autosbatch import SlurmPool","title":"Import"},{"location":"usage/#submit-single-job","text":"run sleep 10 on node cpu01 on cpuPartition paritition. SlurmPool () . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = 'sleep 10' , job_name = 'test' , job_id = '001' ) or run a job containing two steps, e.g. echo hello and sleep 10 SlurmPool () . single_submit ( partition = 'cpuPartition' , node = 'cpu01' , cpus_per_task = 1 , cmds = [ 'echo hello' , 'sleep 10' ], job_name = 'test' , job_id = '001' )","title":"submit single job"},{"location":"usage/#submit-multiple-job","text":"TODO: compare multiprocessing.Pool.map TODO: add with syntax Just like multiprocessing.Pool.map # construct the excutor def sleep ( time ): cmd = f 'sleep { time } ' return cmd # prepare the param for each excutor params = range ( 10 ) # submit to parallel run p = SlurmPool ( 10 ) p . map ( sleep , params ) multiple parameters (similar with multiprocessing.Pool.starmap ) # construct the excutor def echo_sleep ( text , time ): cmd = f 'echo { text } && sleep { time } ' return cmd # prepare the params for each excutor params = [] for text in range ( 5 ): for time in range ( 6 ): params . append ([ text , time ]) # submit to parallel run p = SlurmPool ( 10 ) p . starmap ( echo_sleep , params ) The sbatch scripts are put in ./autosbatch/$timenow/script . The error and stdout logs are in ./autosbatch/$timenow/log . remove script dir: SlurmPool . clean () Custom the job Pool: p = SlurmPool ( pool_size = None , #how many jobs run in parallel, use all resources if not specify. ncpus_per_job = 2 , #how many cpus per job use max_jobs_per_node = None , #how many jobs can a node run at most node_list = None # use all nodes if not specify )","title":"submit multiple job"},{"location":"usage/#usage-for-cli-tool","text":"","title":"Usage for CLI tool"},{"location":"usage/#help-message","text":"$ autosbatch --help Usage: autosbatch [ OPTIONS ] COMMAND [ ARGS ] ... Submit jobs to slurm cluster, without writing slurm script files. \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --version -V Show version. \u2502 \u2502 --verbose -v Show verbose info. \u2502 \u2502 --dev Show dev info. \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 clean Remove all scripts and logs. \u2502 \u2502 multi-job Submit multiple jobs to slurm cluster. \u2502 \u2502 single-job Submit a single job to slurm cluster. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f","title":"help message"},{"location":"usage/#command-single-job","text":"$ autosbatch single-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch single-job [ OPTIONS ] CMD... Submit a single job to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmd CMD... Command to run. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --ncpus -n INTEGER Number of cpus. [ default: 1 ] \u2502 \u2502 --node -N TEXT Node to submit job to. [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs to. [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. [ default: job ] \u2502 \u2502 --help -h Show this message and exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f run example command such as sleep 10 autosbatch single-job sleep 10 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :13:46 ] WARNING Hyperthreading is enabled on cpu14, ncpus_per_job is set to 2 .","title":"Command: single-job"},{"location":"usage/#command-multi-job","text":"$ autosbatch multi-job -h \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Usage: autosbatch multi-job [ OPTIONS ] CMDFILE Submit multiple jobs to slurm cluster. \u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 * cmdfile PATH Path to the command file. [ default: None ] [ required ] \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 --pool-size -p INTEGER RANGE Number of jobs to submit \u2502 \u2502 [ 0 < = x< = 1000 ] at the same time. \u2502 \u2502 [ default: None ] \u2502 \u2502 --ncpus-per-job -n INTEGER Number of cpus per job. \u2502 \u2502 [ default: 1 ] \u2502 \u2502 --max-jobs-per-node -m INTEGER Maximum number of jobs \u2502 \u2502 to submit to a single \u2502 \u2502 node. \u2502 \u2502 [ default: None ] \u2502 \u2502 --node-list -l TEXT List of nodes to submit \u2502 \u2502 jobs to. e.g. \"-l node1 \u2502 \u2502 -l node2 -l node3\" \u2502 \u2502 [ default: None ] \u2502 \u2502 --partition -P TEXT Partition to submit jobs \u2502 \u2502 to. \u2502 \u2502 [ default: None ] \u2502 \u2502 --job-name -j TEXT Name of the job. \u2502 \u2502 [ default: job ] \u2502 \u2502 --help -h Show this message and \u2502 \u2502 exit. \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f submit 10 commands to slurm Step1. write the commands into a text file, one command per line. $ cat ./cmd.sh sleep 0 sleep 1 sleep 2 sleep 3 sleep 4 sleep 5 sleep 6 sleep 7 sleep 8 sleep 9 Step2 run multi-job command $ autosbatch multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00","title":"Command: multi-job"},{"location":"usage/#command-clean","text":"remove the directory contains scripts and logs autosbatch clean","title":"Command: clean"},{"location":"usage/#enable-verbose","text":"add -v or --verbose between autosbatch and command e.g.: $ autosbatch -v multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [ 22 :21:44 ] INFO Verbose mode is on. INFO Found 2 available nodes. INFO 10 jobs to excute, allocated to 6 tasks. INFO Each task will use 1 cpus. INFO Used 2 nodes. INFO Each node will excute 3 tasks in parallel. INFO { 'gpu02' : 3 , 'gpu03' : 3 } INFO gpu02: 3 tasks INFO Task 0 : containing job 0 -1 INFO Sumbitted Task: job_000 to gpu02, containing 2 jobs. Slurm ID: 254554 [ 22 :21:45 ] INFO Task 1 : containing job 2 -3 INFO Sumbitted Task: job_001 to gpu02, containing 2 jobs. Slurm ID: 254555 INFO Task 2 : containing job 4 -5 [ 22 :21:46 ] INFO Sumbitted Task: job_002 to gpu02, containing 2 jobs. Slurm ID: 254556 INFO gpu03: 3 tasks INFO Task 3 : containing job 6 -7 INFO Sumbitted Task: job_003 to gpu03, containing 2 jobs. Slurm ID: 254557 [ 22 :21:47 ] INFO Task 4 : containing job 8 -8 INFO Sumbitted Task: job_004 to gpu03, containing 1 jobs. Slurm ID: 254558 INFO Task 5 : containing job 9 -9 INFO Sumbitted Task: job_005 to gpu03, containing 1 jobs. Slurm ID: 254559 Submitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 Submitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3 /3 0 :00:00 INFO Writing task log to .autosbatch/1219222144/1219222144.log","title":"enable verbose"}]}