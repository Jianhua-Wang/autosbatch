{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#autosbatch","title":"autosbatch","text":"<p>submit hundreds of jobs to slurm automatically</p> <ul> <li>Documentation: https://Jianhua-Wang.github.io/autosbatch</li> <li>GitHub: https://github.com/Jianhua-Wang/autosbatch</li> <li>PyPI: https://pypi.org/project/autosbatch/</li> <li>Free software: MIT</li> </ul>"},{"location":"#features","title":"Features","text":"<p>Sometimes, it's quite inconvenient when we submit hundreds of jobs to slurm. For example, one needs to align RNA-seq data from one hundred samples. He may start with a bash script that takes the fastq of one sample and write sbatch scripts which execute <code>bash align.sh sample.fq</code> multiple times. If he wants to run 50 samples at the same time, he should write 50 sbatch scripts and each script contains two align commands. Manually managing these sbatch scripts is inconvenient. autosbatch is very helpful for submitting slurm jobs automatically and it's just like the <code>multiprocessing.Pool</code>.</p> <ul> <li>Automatically submit hundreds of jobs to Slurm with a few code.</li> <li>The same usage as <code>multiprocessing.Pool</code>.</li> <li>Provide command line tool for people who are not familiar with Python.</li> </ul>"},{"location":"#todo","title":"TODO","text":"<ul> <li>Support gpu allocation</li> <li>Support MPI jobs</li> </ul>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.</p>"},{"location":"api/","title":"Modules","text":"<p>A class for submitting jobs to Slurm.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <code>int</code> <p>Number of jobs to submit at the same time, by default None</p> <code>None</code> <code>ncpus_per_job</code> <code>int</code> <p>Number of cpus per job, by default 1</p> <code>1</code> <code>max_jobs_per_node</code> <code>int</code> <p>Maximum number of jobs to submit to a single node, by default None</p> <code>None</code> <code>node_list</code> <code>List[str]</code> <p>List of nodes to submit jobs to, by default None</p> <code>None</code> <code>partition</code> <code>str</code> <p>Partition to submit jobs to, by default None</p> <code>None</code> <code>max_pool_size</code> <code>int</code> <p>Maximum number of jobs to submit, by default 1000</p> <code>1000</code> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def __init__(\n    self,\n    pool_size: Optional[int] = None,\n    ncpus_per_job: int = 1,\n    max_jobs_per_node: Optional[int] = None,\n    node_list: Optional[List[str]] = None,\n    partition: Optional[str] = None,\n    max_pool_size: int = 1000,\n):\n\"\"\"\n    Initialize a SlurmPool object.\n\n    Parameters\n    ----------\n    pool_size : int, optional\n        Number of jobs to submit at the same time, by default None\n    ncpus_per_job : int, optional\n        Number of cpus per job, by default 1\n    max_jobs_per_node : int, optional\n        Maximum number of jobs to submit to a single node, by default None\n    node_list : List[str], optional\n        List of nodes to submit jobs to, by default None\n    partition : str, optional\n        Partition to submit jobs to, by default None\n    max_pool_size : int, optional\n        Maximum number of jobs to submit, by default 1000\n    \"\"\"\n    self.ncpus_per_job = ncpus_per_job\n    self.logger = logging.getLogger('autosbatch')\n    self.nodes = self.get_nodes()\n    self._get_avail_nodes(node_list=node_list, partition=partition)\n    self.node_list = list(self.nodes.keys())\n    if len(self.node_list) == 0:\n        raise RuntimeError('No Nodes are qualtified.')\n\n    self._set_max_jobs_per_node(max_jobs_per_node=max_jobs_per_node)\n\n    jobs_on_nodes = {k: v['max_jobs'] for k, v in self.nodes.items()}\n    self.jobs_on_nodes = {\n        k: v if v &lt;= self.max_jobs_per_node else self.max_jobs_per_node for k, v in jobs_on_nodes.items()\n    }\n    self._set_pool_size(pool_size=pool_size, max_pool_size=max_pool_size)\n    self.time_now = datetime.datetime.now().strftime('%m%d%H%M%S')\n    self.file_dir = f'{self.dir_path}/{self.time_now}'\n    self.log_dir = f'{self.file_dir}/log'\n    self.scripts_dir = f'{self.file_dir}/scripts'\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.__enter__","title":"<code>__enter__()</code>","text":"<p>Clean up the scripts and log files.</p> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def __enter__(self):\n\"\"\"Clean up the scripts and log files.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Clean up the scripts and log files.</p> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"Clean up the scripts and log files.\"\"\"\n    self.close()\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.clean","title":"<code>clean()</code>  <code>classmethod</code>","text":"<p>Clean up the scripts and log files.</p> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>@classmethod\ndef clean(cls):\n\"\"\"Clean up the scripts and log files.\"\"\"\n    command = ['rm', '-rf', cls.dir_path]\n    _ = run(command, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.close","title":"<code>close()</code>","text":"<p>Clean up the scripts and log files.</p> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def close(self):\n\"\"\"Clean up the scripts and log files.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.get_nodes","title":"<code>get_nodes(sortByload=True)</code>  <code>classmethod</code>","text":"<p>Get nodes information from sinfo.</p> <p>Parameters:</p> Name Type Description Default <code>sortByload</code> <code>bool</code> <p>Sort nodes by load, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict</code> <p>Information of nodes, by default</p> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>@classmethod\ndef get_nodes(cls, sortByload=True) -&gt; Dict:\n\"\"\"\n    Get nodes information from sinfo.\n\n    Parameters\n    ----------\n    sortByload : bool, optional\n        Sort nodes by load, by default True\n\n    Returns\n    -------\n    Dict\n        Information of nodes, by default\n    \"\"\"\n    command = ['sinfo', '-o', '\"%n %e %m %a %c %C %O %R %t\"']\n    result = run(command, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    nodes = {}\n    for line in result.stdout.splitlines():\n        line = line.strip('\\\"')\n        if line.startswith('HOSTNAMES'):\n            continue\n        node, free_mem, memory, avail, cpus, free_cpus, load, partition, state = line.split()\n        free_mem = int(free_mem) if free_mem != 'N/A' else 0\n        memory = int(memory) if memory != 'N/A' else 0\n        load = float(load) if load != 'N/A' else 0\n        nodes[node] = {\n            'free_mem': free_mem,\n            'used_mem': memory - free_mem,\n            'memory': memory,\n            'AVAIL': avail,\n            'cpus': int(cpus),\n            'used_cpus': int(free_cpus.split('/')[0]),\n            'free_cpus': int(free_cpus.split('/')[1]),\n            'load': load,\n            'partition': partition,\n            'state': state,\n        }\n    if sortByload:\n        nodes = dict(\n            OrderedDict(sorted(nodes.items(), key=lambda x: (x[1]['load'], x[1]['used_mem'], x[1]['used_cpus'])))\n        )\n    return nodes\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.map","title":"<code>map(func, params)</code>","text":"<p>Submit a list of commands to the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function to call</p> required <code>params</code> <code>Iterable</code> <p>Parameters to pass to the function</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def map(self, func: Callable, params: Iterable):\n\"\"\"\n    Submit a list of commands to the cluster.\n\n    Parameters\n    ----------\n    func : Callable\n        Function to call\n    params : Iterable\n        Parameters to pass to the function\n\n    Returns\n    -------\n    None\n    \"\"\"\n    cmds = [func(i) for i in params]\n    self.multi_submit(cmds, func.__name__)\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.multi_submit","title":"<code>multi_submit(cmds, job_name, shuffle=False, sleep_time=0.5)</code>","text":"<p>Submit jobs to multiple nodes.</p> <p>Parameters:</p> Name Type Description Default <code>cmds</code> <code>List[str]</code> <p>Commands to run</p> required <code>job_name</code> <code>str</code> <p>Name of the job</p> required <code>logging_level</code> <code>int</code> <p>Logging level, by default logging.WARNING</p> required <code>shuffle</code> <code>bool</code> <p>Shuffle the commands, by default False</p> <code>False</code> <code>sleep_time</code> <code>float</code> <p>Time to sleep between each submission, by default 0.5</p> <code>0.5</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def multi_submit(\n    self,\n    cmds: List[str],\n    job_name: str,\n    # logging_level: int = logging.WARNING,\n    shuffle: bool = False,\n    sleep_time: float = 0.5,\n):\n\"\"\"\n    Submit jobs to multiple nodes.\n\n    Parameters\n    ----------\n    cmds : List[str]\n        Commands to run\n    job_name : str\n        Name of the job\n    logging_level : int, optional\n        Logging level, by default logging.WARNING\n    shuffle : bool, optional\n        Shuffle the commands, by default False\n    sleep_time : float, optional\n        Time to sleep between each submission, by default 0.5\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if shuffle:\n        import random\n\n        random.shuffle(cmds)\n    # self.logger.setLevel(logging_level)\n    self.logger.info(f'Found {len(self.nodes)} available nodes.')\n    self.pool_size = min(self.pool_size, len(cmds))\n    self.logger.info(f'{len(cmds):,} jobs to excute, allocated to {self.pool_size} tasks.')\n    self.logger.info(f'Each task will use {self.ncpus_per_job} cpus.')\n\n    used_nodes = {}\n    registed_jobs = 0\n    for k, v in self.jobs_on_nodes.items():\n        used_nodes[k] = v\n        registed_jobs += v\n        if registed_jobs &lt; self.pool_size:\n            continue\n        elif registed_jobs == self.pool_size:\n            break\n        else:\n            used_nodes[k] -= registed_jobs - self.pool_size\n            break\n    self.logger.info(f'Used {len(used_nodes)} nodes.')\n    self.logger.info(f'Each node will excute {max(used_nodes.values())} tasks in parallel.')\n    self.logger.info(f'{used_nodes}')\n    k, m = divmod(len(cmds), self.pool_size)\n    ith = 0\n    task_log = {}\n    with Progress(\n        TextColumn(\"{task.description}\"),\n        BarColumn(),\n        MofNCompleteColumn(),\n        TimeRemainingColumn(),\n        auto_refresh=False,\n    ) as progress:\n        for node, n_jobs in used_nodes.items():\n            self.logger.info(f'{node}: {n_jobs} tasks')\n            task = progress.add_task(f\"Submitting to {node}...\", total=n_jobs)\n            for _ in range(n_jobs):\n                time.sleep(sleep_time)\n                start, end = ith * k + min(ith, m), (ith + 1) * k + min(ith + 1, m)\n                self.logger.info(f'Task {ith}: containing job {start}-{end-1}')\n                task_name = f'{job_name}_{ith:&gt;03}'\n                self.single_submit(\n                    self.nodes[node]['partition'],\n                    node,\n                    self.ncpus_per_job,\n                    cmds[start:end],\n                    task_name,\n                    # logging_level,\n                )\n                progress.update(task, advance=1)\n                progress.refresh()\n                ith += 1\n                task_log[task_name] = {\n                    'node': node,\n                    'script': f'{task_name}.sh',\n                    'stdout': f'{task_name}.out.log',\n                    'stderr': f'{task_name}.err.log',\n                    'cmd': cmds[start:end],\n                }\n    with open(f'{self.file_dir}/{self.time_now}.log', 'w') as f:\n        self.logger.info(f'Writing task log to {self.file_dir}/{self.time_now}.log')\n        json.dump(task_log, f, indent=4)\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.single_submit","title":"<code>single_submit(partition, node, cpus_per_task, cmds, job_name='job')</code>","text":"<p>Submit a single job.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>str</code> <p>Partition to submit jobs to</p> required <code>node</code> <code>str</code> <p>Node to submit jobs to</p> required <code>cpus_per_task</code> <code>int</code> <p>Number of CPUs to use</p> required <code>cmds</code> <code>str or List[str]</code> <p>Commands to run</p> required <code>job_name</code> <code>str</code> <p>Name of the job, by default 'job'</p> <code>'job'</code> <code>logging_level</code> <code>int</code> <p>Logging level, by default logging.WARNING</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def single_submit(\n    self,\n    partition: str,\n    node: str,\n    cpus_per_task: int,\n    cmds: Union[str, List[str]],\n    job_name: str = 'job',\n    # logging_level: int = logging.WARNING,\n):\n\"\"\"\n    Submit a single job.\n\n    Parameters\n    ----------\n    partition : str\n        Partition to submit jobs to\n    node : str\n        Node to submit jobs to\n    cpus_per_task : int\n        Number of CPUs to use\n    cmds : str or List[str]\n        Commands to run\n    job_name : str, optional\n        Name of the job, by default 'job'\n    logging_level : int, optional\n        Logging level, by default logging.WARNING\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # self.logger.setLevel(logging_level)\n    Path(self.scripts_dir).mkdir(parents=True, exist_ok=True)\n    Path(self.log_dir).mkdir(parents=True, exist_ok=True)\n    templateLoader = FileSystemLoader(searchpath=f\"{os.path.dirname(os.path.realpath(__file__))}/template\")\n    env = Environment(loader=templateLoader)\n    template = env.get_template(self.CPU_OpenMP_TEMPLATE)\n\n    if isinstance(cmds, str):\n        cmds = [cmds]\n    output_from_parsed_template = template.render(\n        job_name=job_name,\n        partition=partition,\n        node=node,\n        cpus_per_task=cpus_per_task,\n        cmds='\\n'.join(cmds),\n        log_dir=self.log_dir,\n    )\n    script_path = f'{self.scripts_dir}/{job_name}.sh'\n    with open(script_path, 'w') as f:\n        f.write(output_from_parsed_template)\n    command = ['chmod', '755', script_path]\n    _ = run(command, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    command = ['sbatch', script_path]\n    result = run(command, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    slurm_id = result.stdout.strip().split()[-1]\n    self.logger.info(f'Sumbitted Task: {job_name} to {node}, containing {len(cmds)} jobs. Slurm ID: {slurm_id}')\n    self.logger.debug(f'Commands: {cmds}')\n</code></pre>"},{"location":"api/#autosbatch.SlurmPool.starmap","title":"<code>starmap(func, params)</code>","text":"<p>Submit a list of commands to the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function to call</p> required <code>params</code> <code>Iterable[Iterable]</code> <p>Parameters to pass to the function</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>autosbatch/autosbatch.py</code> <pre><code>def starmap(self, func: Callable, params: Iterable[Iterable]):\n\"\"\"\n    Submit a list of commands to the cluster.\n\n    Parameters\n    ----------\n    func : Callable\n        Function to call\n    params : Iterable[Iterable]\n        Parameters to pass to the function\n\n    Returns\n    -------\n    None\n    \"\"\"\n    cmds = [func(*i) for i in params]\n    self.multi_submit(cmds, func.__name__)\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#027-2023-09-25","title":"[0.2.7] - 2023-09-25","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#changed","title":"Changed","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>fix dependencies</li> </ul>"},{"location":"changelog/#022-2023-03-01","title":"[0.2.2] - 2023-03-01","text":""},{"location":"changelog/#added_1","title":"Added","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>change log level to warning</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":""},{"location":"changelog/#021-2023-03-01","title":"[0.2.1] - 2023-03-01","text":""},{"location":"changelog/#added_2","title":"Added","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>change rich version to 13.3.1</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":""},{"location":"changelog/#020-2023-03-01","title":"[0.2.0] - 2023-03-01","text":""},{"location":"changelog/#added_3","title":"Added","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>change log level to info</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":""},{"location":"changelog/#019-2023-02-08","title":"[0.1.9] - 2023-02-08","text":""},{"location":"changelog/#added_4","title":"Added","text":""},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>change log file dir to init</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>log file directory is class atribute</li> </ul>"},{"location":"changelog/#018-2022-12-19","title":"[0.1.8] - 2022-12-19","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>add api docs</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":""},{"location":"changelog/#fixed_5","title":"Fixed","text":""},{"location":"changelog/#017-2022-12-19","title":"[0.1.7] - 2022-12-19","text":""},{"location":"changelog/#added_6","title":"Added","text":""},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>disable auto_refresh progress bar</li> </ul>"},{"location":"changelog/#fixed_6","title":"Fixed","text":""},{"location":"changelog/#010-2022-12-16","title":"[0.1.0] - 2022-12-16","text":"<p>Here we would have the update steps for 1.2.4 for people to follow.</p>"},{"location":"changelog/#added_7","title":"Added","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>PROJECTNAME-ZZZZ   PATCH Drupal.org is now used for composer.</li> </ul>"},{"location":"changelog/#fixed_7","title":"Fixed","text":"<ul> <li>PROJECTNAME-TTTT   PATCH Add logic to runsheet teaser delete to delete corresponding   schedule cards.</li> </ul>"},{"location":"changelog/#011-2022-12-16","title":"[0.1.1] - 2022-12-16","text":""},{"location":"changelog/#added_8","title":"Added","text":""},{"location":"changelog/#changed_8","title":"Changed","text":""},{"location":"changelog/#fixed_8","title":"Fixed","text":"<ul> <li>PROJECTNAME-UUUU   MINOR Fix module foo tests</li> <li>PROJECTNAME-RRRR   MAJOR Module foo's timeline uses the browser timezone for date resolution</li> </ul>"},{"location":"changelog/#012-2022-12-16","title":"[0.1.2] - 2022-12-16","text":""},{"location":"changelog/#added_9","title":"Added","text":""},{"location":"changelog/#changed_9","title":"Changed","text":""},{"location":"changelog/#fixed_9","title":"Fixed","text":"<ul> <li>PROJECTNAME-UUUU   MINOR Fix module foo tests</li> <li>PROJECTNAME-RRRR   MAJOR Module foo's timeline uses the browser timezone for date resolution</li> </ul>"},{"location":"changelog/#013-2022-12-17","title":"[0.1.3] - 2022-12-17","text":""},{"location":"changelog/#added_10","title":"Added","text":""},{"location":"changelog/#changed_10","title":"Changed","text":"<ul> <li>Reconstruct the project structure</li> </ul>"},{"location":"changelog/#fixed_10","title":"Fixed","text":""},{"location":"changelog/#014-2022-12-18","title":"[0.1.4] - 2022-12-18","text":""},{"location":"changelog/#added_11","title":"Added","text":""},{"location":"changelog/#changed_11","title":"Changed","text":"<ul> <li>Use jinja2 as sbatch template</li> <li>change script dir to .autosbatch</li> <li>get rid of pandas</li> <li>replace call with subprocess.run</li> <li>speed up by remove append</li> <li>Add a logger</li> <li>save job information to a file</li> </ul>"},{"location":"changelog/#fixed_11","title":"Fixed","text":""},{"location":"changelog/#015-2022-12-19","title":"[0.1.5] - 2022-12-19","text":""},{"location":"changelog/#added_12","title":"Added","text":"<ul> <li>clean command</li> <li>multi submit command</li> <li>single submit command</li> </ul>"},{"location":"changelog/#changed_12","title":"Changed","text":"<ul> <li>replace click with typer</li> </ul>"},{"location":"changelog/#fixed_12","title":"Fixed","text":""},{"location":"changelog/#016-2022-12-19","title":"[0.1.6] - 2022-12-19","text":""},{"location":"changelog/#added_13","title":"Added","text":"<ul> <li>support context manager</li> <li>add docs</li> </ul>"},{"location":"changelog/#changed_13","title":"Changed","text":""},{"location":"changelog/#fixed_13","title":"Fixed","text":""},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/Jianhua-Wang/autosbatch/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>autosbatch could always use more documentation, whether as part of the official autosbatch docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/Jianhua-Wang/autosbatch/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>autosbatch</code> for local development.</p> <ol> <li>Fork the <code>autosbatch</code> repo on GitHub.</li> <li> <p>Clone your fork locally</p> <pre><code>$ git clone git@github.com:your_name_here/autosbatch.git\n</code></pre> </li> <li> <p>Ensure poetry is installed.</p> </li> <li> <p>Install dependencies and start your virtualenv:</p> <pre><code>$ poetry install -E test -E doc -E dev\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass the    tests, including testing other Python versions, with tox:</p> <pre><code>$ poetry run tox\n</code></pre> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.md.</li> <li>The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check    https://github.com/Jianhua-Wang/autosbatch/actions    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"contributing/#tips","title":"Tips","text":"<pre><code>$ poetry run pytest tests/test_autosbatch.py\n</code></pre> <p>To run a subset of tests.</p>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run:</p> <pre><code>$ poetry run bump2version patch # possible: major / minor / patch\n$ git push\n$ git push --tags\n</code></pre> <p>GitHub Actions will then deploy to PyPI if tests pass.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install autosbatch, run this command in your terminal:</p> <pre><code>$ pip install autosbatch\n</code></pre> <p>This is the preferred method to install autosbatch, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for autosbatch can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>$ git clone git://github.com/Jianhua-Wang/autosbatch\n</code></pre> <p>Or download the tarball:</p> <pre><code>$ curl -OJL https://github.com/Jianhua-Wang/autosbatch/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>$ pip install .\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage-for-package","title":"Usage for package","text":""},{"location":"usage/#import","title":"Import","text":"<pre><code>import autosbatch\n# or import SlurmPool directly\nfrom autosbatch import SlurmPool\n</code></pre>"},{"location":"usage/#submit-single-job","title":"submit single job","text":"<p>run <code>sleep 10</code> on node <code>cpu01</code> on <code>cpuPartition</code> paritition. <pre><code>SlurmPool().single_submit(partition='cpuPartition',\n                        node='cpu01',\n                        cpus_per_task=1,\n                        cmds='sleep 10',\n                        job_name='test',\n                        job_id='001')\n</code></pre></p> <p>or run a job containing two steps, e.g. <code>echo hello</code> and <code>sleep 10</code> <pre><code>SlurmPool().single_submit(partition='cpuPartition',\n                        node='cpu01',\n                        cpus_per_task=1,\n                        cmds=['echo hello','sleep 10'],\n                        job_name='test',\n                        job_id='001')\n</code></pre></p>"},{"location":"usage/#submit-multiple-job","title":"submit multiple job","text":"<p>TODO: compare multiprocessing.Pool.map TODO: add with syntax</p> <p>Just like <code>multiprocessing.Pool.map</code> <pre><code># construct the excutor\ndef sleep(time):\n    cmd = f'sleep {time}'\n    return cmd\n\n# prepare the param for each excutor\nparams = range(10)\n\n# submit to parallel run\np = SlurmPool(10)\np.map(sleep, params)\n</code></pre></p> <p>multiple parameters (similar with <code>multiprocessing.Pool.starmap</code>)</p> <pre><code># construct the excutor\ndef echo_sleep(text, time):\n    cmd = f'echo {text} &amp;&amp; sleep {time}'\n    return cmd\n\n# prepare the params for each excutor\nparams = []\nfor text in range(5):\n    for time in range(6):\n        params.append([text, time])\n\n# submit to parallel run\np = SlurmPool(10)\np.starmap(echo_sleep, params)\n</code></pre> <p>The sbatch scripts are put in <code>./autosbatch/$timenow/script</code>. The error and stdout logs are in <code>./autosbatch/$timenow/log</code>.</p> <p>remove <code>script</code> dir:</p> <pre><code>SlurmPool.clean()\n</code></pre> <p>Custom the job Pool: <pre><code>p = SlurmPool(  pool_size=None, #how many jobs run in parallel, use all resources if not specify.\n                ncpus_per_job=2, #how many cpus per job use\n                max_jobs_per_node=None, #how many jobs can a node run at most\n                node_list=None # use all nodes if not specify\n                )\n</code></pre></p>"},{"location":"usage/#usage-for-cli-tool","title":"Usage for CLI tool","text":""},{"location":"usage/#help-message","title":"help message","text":"<pre><code>$ autosbatch --help\n\n Usage: autosbatch [OPTIONS] COMMAND [ARGS]...\n\n Submit jobs to slurm cluster, without writing slurm script files.\n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --version  -V        Show version.                                              \u2502\n\u2502 --verbose  -v        Show verbose info.                                         \u2502\n\u2502 --dev                Show dev info.                                             \u2502\n\u2502 --help     -h        Show this message and exit.                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 clean              Remove all scripts and logs.                                 \u2502\n\u2502 multi-job          Submit multiple jobs to slurm cluster.                       \u2502\n\u2502 single-job         Submit a single job to slurm cluster.                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"usage/#command-single-job","title":"Command: single-job","text":"<pre><code>$ autosbatch single-job -h\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n Usage: autosbatch single-job [OPTIONS] CMD...\n\n Submit a single job to slurm cluster.\n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *    cmd      CMD...  Command to run. [default: None] [required]                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --ncpus      -n      INTEGER  Number of cpus. [default: 1]                      \u2502\n\u2502 --node       -N      TEXT     Node to submit job to. [default: None]            \u2502\n\u2502 --partition  -P      TEXT     Partition to submit jobs to. [default: None]      \u2502\n\u2502 --job-name   -j      TEXT     Name of the job. [default: job]                   \u2502\n\u2502 --help       -h               Show this message and exit.                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>run example command such as <code>sleep 10</code> <pre><code>autosbatch single-job sleep 10\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n[22:13:46] WARNING  Hyperthreading is enabled on cpu14, ncpus_per_job is set to 2.\n</code></pre></p>"},{"location":"usage/#command-multi-job","title":"Command: multi-job","text":"<pre><code>$ autosbatch multi-job -h\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n Usage: autosbatch multi-job [OPTIONS] CMDFILE\n\n Submit multiple jobs to slurm cluster.\n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *    cmdfile      PATH  Path to the command file. [default: None] [required]    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --pool-size          -p      INTEGER RANGE             Number of jobs to submit \u2502\n\u2502                              [0&lt;=x&lt;=1000]              at the same time.        \u2502\n\u2502                                                        [default: None]          \u2502\n\u2502 --ncpus-per-job      -n      INTEGER                   Number of cpus per job.  \u2502\n\u2502                                                        [default: 1]             \u2502\n\u2502 --max-jobs-per-node  -m      INTEGER                   Maximum number of jobs   \u2502\n\u2502                                                        to submit to a single    \u2502\n\u2502                                                        node.                    \u2502\n\u2502                                                        [default: None]          \u2502\n\u2502 --node-list          -l      TEXT                      List of nodes to submit  \u2502\n\u2502                                                        jobs to. e.g. \"-l node1  \u2502\n\u2502                                                        -l node2 -l node3\"       \u2502\n\u2502                                                        [default: None]          \u2502\n\u2502 --partition          -P      TEXT                      Partition to submit jobs \u2502\n\u2502                                                        to.                      \u2502\n\u2502                                                        [default: None]          \u2502\n\u2502 --job-name           -j      TEXT                      Name of the job.         \u2502\n\u2502                                                        [default: job]           \u2502\n\u2502 --help               -h                                Show this message and    \u2502\n\u2502                                                        exit.                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>submit 10 commands to slurm</p> <p>Step1. write the commands into a text file, one command per line. <pre><code>$ cat ./cmd.sh\nsleep 0\nsleep 1\nsleep 2\nsleep 3\nsleep 4\nsleep 5\nsleep 6\nsleep 7\nsleep 8\nsleep 9\n</code></pre></p> <p>Step2 run <code>multi-job</code> command <pre><code>$ autosbatch multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSubmitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3/3 0:00:00\nSubmitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3/3 0:00:00\n</code></pre></p>"},{"location":"usage/#command-clean","title":"Command: clean","text":"<p>remove the directory contains scripts and logs <pre><code>autosbatch clean\n</code></pre></p>"},{"location":"usage/#enable-verbose","title":"enable <code>verbose</code>","text":"<p>add <code>-v</code> or <code>--verbose</code> between <code>autosbatch</code> and <code>command</code></p> <p>e.g.: <pre><code>$ autosbatch -v multi-job --max-jobs-per-node 3 -P gpu -l gpu02 -l gpu03 ./cmd.sh\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 AutoSbatch \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n[22:21:44] INFO     Verbose mode is on.\n           INFO     Found 2 available nodes.\n           INFO     10 jobs to excute, allocated to 6 tasks.\n           INFO     Each task will use 1 cpus.\n           INFO     Used 2 nodes.\n           INFO     Each node will excute 3 tasks in parallel.\n           INFO     {'gpu02': 3, 'gpu03': 3}\nINFO     gpu02: 3 tasks\n           INFO     Task 0: containing job 0-1\n           INFO     Sumbitted Task: job_000 to gpu02, containing 2 jobs. Slurm ID: 254554\n[22:21:45] INFO     Task 1: containing job 2-3\n           INFO     Sumbitted Task: job_001 to gpu02, containing 2 jobs. Slurm ID: 254555\nINFO     Task 2: containing job 4-5\n[22:21:46] INFO     Sumbitted Task: job_002 to gpu02, containing 2 jobs. Slurm ID: 254556\nINFO     gpu03: 3 tasks\n           INFO     Task 3: containing job 6-7\n           INFO     Sumbitted Task: job_003 to gpu03, containing 2 jobs. Slurm ID: 254557\n[22:21:47] INFO     Task 4: containing job 8-8\n           INFO     Sumbitted Task: job_004 to gpu03, containing 1 jobs. Slurm ID: 254558\nINFO     Task 5: containing job 9-9\n           INFO     Sumbitted Task: job_005 to gpu03, containing 1 jobs. Slurm ID: 254559\nSubmitting to gpu02... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3/3 0:00:00\nSubmitting to gpu03... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3/3 0:00:00\n           INFO     Writing task log to .autosbatch/1219222144/1219222144.log\n</code></pre></p>"}]}